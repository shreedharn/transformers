
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../transformers_advanced/">
      
      
        <link rel="next" href="../pytorch_ref/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>Knowledge Store - Introduction to Transformers</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../styles.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#llm-weights-vs-vector-stores-knowledge-storage-and-similarity-calculations" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Introduction to Transformers" class="md-header__button md-logo" aria-label="Introduction to Transformers" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Introduction to Transformers
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Knowledge Store
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Introduction to Transformers" class="md-nav__button md-logo" aria-label="Introduction to Transformers" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Introduction to Transformers
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../nn_intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Neural Network Introduction
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../mlp_intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Building Networks with MLP
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../rnn_intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Sequential Modeling with RNN
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers_fundamentals/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transformers Fundamentals
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers_advanced/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transformers Advanced
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Knowledge Store
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Knowledge Store
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#part-i-knowledge-storage-mechanisms" class="md-nav__link">
    <span class="md-ellipsis">
      PART I: Knowledge Storage Mechanisms
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PART I: Knowledge Storage Mechanisms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-llm-weights" class="md-nav__link">
    <span class="md-ellipsis">
      1. LLM Weights
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. LLM Weights">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#introduction-how-knowledge-becomes-internalized-in-llm-weights" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction: How Knowledge Becomes Internalized in LLM Weights
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#weight-computation-timeline-and-lifecycle" class="md-nav__link">
    <span class="md-ellipsis">
      Weight Computation Timeline and Lifecycle
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hidden-states-and-weight-interaction" class="md-nav__link">
    <span class="md-ellipsis">
      Hidden States and Weight Interaction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-head-attention-why-multiple-perspectives-matter" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Head Attention: Why Multiple Perspectives Matter
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#understanding-scale-what-does-billion-parameters-actually-mean" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Scale: What Does "Billion Parameters" Actually Mean?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-vector-store-knowledge-storage" class="md-nav__link">
    <span class="md-ellipsis">
      2. Vector Store Knowledge Storage
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Vector Store Knowledge Storage">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#introduction-what-are-vector-stores" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction: What Are Vector Stores?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-vector-search-works-from-simple-to-sophisticated" class="md-nav__link">
    <span class="md-ellipsis">
      How Vector Search Works: From Simple to Sophisticated
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-indexing-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Indexing Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from-theory-to-practice-implementing-vector-search" class="md-nav__link">
    <span class="md-ellipsis">
      From Theory to Practice: Implementing Vector Search
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprehensive-hands-on-tutorial" class="md-nav__link">
    <span class="md-ellipsis">
      Comprehensive Hands-on Tutorial
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#understanding-index-performance-trade-offs" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Index Performance Trade-offs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-database-terminology-and-index-implementations" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Database Terminology and Index Implementations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-database-operations-and-production-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Database Operations and Production Considerations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-ii-generation-and-retrieval-control" class="md-nav__link">
    <span class="md-ellipsis">
      PART II: Generation and Retrieval Control
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PART II: Generation and Retrieval Control">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#3-controlling-randomness-temperature-top-k-and-top-p-in-llms-and-vector-stores" class="md-nav__link">
    <span class="md-ellipsis">
      3. Controlling Randomness: Temperature, Top-K, and Top-P in LLMs and Vector Stores
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Controlling Randomness: Temperature, Top-K, and Top-P in LLMs and Vector Stores">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#temperature-top-k-top-p-in-llm-text-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Temperature, Top-K, Top-P in LLM Text Generation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-vector-stores-handle-search-control" class="md-nav__link">
    <span class="md-ellipsis">
      How Vector Stores Handle Search Control
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-iii-mathematical-foundations" class="md-nav__link">
    <span class="md-ellipsis">
      PART III: Mathematical Foundations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PART III: Mathematical Foundations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#comprehensive-mathematical-resources" class="md-nav__link">
    <span class="md-ellipsis">
      Comprehensive Mathematical Resources
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Comprehensive Mathematical Resources">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#transformers-mathematics-guide-part-1" class="md-nav__link">
    <span class="md-ellipsis">
      Transformers Mathematics Guide Part 1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformers-mathematics-guide-part-2" class="md-nav__link">
    <span class="md-ellipsis">
      Transformers Mathematics Guide Part 2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-quick-reference" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Quick Reference
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-foundations-summary" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundations Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-iv-system-comparison-and-integration" class="md-nav__link">
    <span class="md-ellipsis">
      PART IV: System Comparison and Integration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PART IV: System Comparison and Integration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#4-critical-question-are-they-the-same-concept" class="md-nav__link">
    <span class="md-ellipsis">
      4. Critical Question: Are They the Same Concept?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-similarity-calculations-across-systems" class="md-nav__link">
    <span class="md-ellipsis">
      5. Similarity Calculations Across Systems
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Similarity Calculations Across Systems">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-llms-use-similarity" class="md-nav__link">
    <span class="md-ellipsis">
      How LLMs Use Similarity
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-vector-stores-use-similarity" class="md-nav__link">
    <span class="md-ellipsis">
      How Vector Stores Use Similarity
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6-practical-integration" class="md-nav__link">
    <span class="md-ellipsis">
      6. Practical Integration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Practical Integration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#complementary-systems" class="md-nav__link">
    <span class="md-ellipsis">
      Complementary Systems
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#concrete-comparative-example" class="md-nav__link">
    <span class="md-ellipsis">
      Concrete Comparative Example
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#system-limitations-and-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      System Limitations and Considerations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Conclusion">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-distinctions" class="md-nav__link">
    <span class="md-ellipsis">
      Key Distinctions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unified-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      Unified Understanding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practical-integration" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Integration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    References
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            References
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch_ref/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    PyTorch Primer
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers_math1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Mathematical Foundations 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers_math2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Mathematical Foundations 2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../math_quick_ref/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Mathematical Quick Reference
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../history_quick_ref/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Sequence Modeling History
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../glossary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Glossary
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    README
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../LICENSE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LICENSE
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#part-i-knowledge-storage-mechanisms" class="md-nav__link">
    <span class="md-ellipsis">
      PART I: Knowledge Storage Mechanisms
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PART I: Knowledge Storage Mechanisms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-llm-weights" class="md-nav__link">
    <span class="md-ellipsis">
      1. LLM Weights
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. LLM Weights">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#introduction-how-knowledge-becomes-internalized-in-llm-weights" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction: How Knowledge Becomes Internalized in LLM Weights
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#weight-computation-timeline-and-lifecycle" class="md-nav__link">
    <span class="md-ellipsis">
      Weight Computation Timeline and Lifecycle
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hidden-states-and-weight-interaction" class="md-nav__link">
    <span class="md-ellipsis">
      Hidden States and Weight Interaction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-head-attention-why-multiple-perspectives-matter" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Head Attention: Why Multiple Perspectives Matter
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#understanding-scale-what-does-billion-parameters-actually-mean" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Scale: What Does "Billion Parameters" Actually Mean?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-vector-store-knowledge-storage" class="md-nav__link">
    <span class="md-ellipsis">
      2. Vector Store Knowledge Storage
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. Vector Store Knowledge Storage">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#introduction-what-are-vector-stores" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction: What Are Vector Stores?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-vector-search-works-from-simple-to-sophisticated" class="md-nav__link">
    <span class="md-ellipsis">
      How Vector Search Works: From Simple to Sophisticated
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-indexing-methods" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Indexing Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from-theory-to-practice-implementing-vector-search" class="md-nav__link">
    <span class="md-ellipsis">
      From Theory to Practice: Implementing Vector Search
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#comprehensive-hands-on-tutorial" class="md-nav__link">
    <span class="md-ellipsis">
      Comprehensive Hands-on Tutorial
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#understanding-index-performance-trade-offs" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Index Performance Trade-offs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-database-terminology-and-index-implementations" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Database Terminology and Index Implementations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vector-database-operations-and-production-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Vector Database Operations and Production Considerations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-ii-generation-and-retrieval-control" class="md-nav__link">
    <span class="md-ellipsis">
      PART II: Generation and Retrieval Control
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PART II: Generation and Retrieval Control">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#3-controlling-randomness-temperature-top-k-and-top-p-in-llms-and-vector-stores" class="md-nav__link">
    <span class="md-ellipsis">
      3. Controlling Randomness: Temperature, Top-K, and Top-P in LLMs and Vector Stores
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Controlling Randomness: Temperature, Top-K, and Top-P in LLMs and Vector Stores">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#temperature-top-k-top-p-in-llm-text-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Temperature, Top-K, Top-P in LLM Text Generation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-vector-stores-handle-search-control" class="md-nav__link">
    <span class="md-ellipsis">
      How Vector Stores Handle Search Control
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-iii-mathematical-foundations" class="md-nav__link">
    <span class="md-ellipsis">
      PART III: Mathematical Foundations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PART III: Mathematical Foundations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#comprehensive-mathematical-resources" class="md-nav__link">
    <span class="md-ellipsis">
      Comprehensive Mathematical Resources
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Comprehensive Mathematical Resources">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#transformers-mathematics-guide-part-1" class="md-nav__link">
    <span class="md-ellipsis">
      Transformers Mathematics Guide Part 1
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#transformers-mathematics-guide-part-2" class="md-nav__link">
    <span class="md-ellipsis">
      Transformers Mathematics Guide Part 2
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-quick-reference" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Quick Reference
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-foundations-summary" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundations Summary
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-iv-system-comparison-and-integration" class="md-nav__link">
    <span class="md-ellipsis">
      PART IV: System Comparison and Integration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PART IV: System Comparison and Integration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#4-critical-question-are-they-the-same-concept" class="md-nav__link">
    <span class="md-ellipsis">
      4. Critical Question: Are They the Same Concept?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5-similarity-calculations-across-systems" class="md-nav__link">
    <span class="md-ellipsis">
      5. Similarity Calculations Across Systems
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Similarity Calculations Across Systems">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#how-llms-use-similarity" class="md-nav__link">
    <span class="md-ellipsis">
      How LLMs Use Similarity
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#how-vector-stores-use-similarity" class="md-nav__link">
    <span class="md-ellipsis">
      How Vector Stores Use Similarity
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#6-practical-integration" class="md-nav__link">
    <span class="md-ellipsis">
      6. Practical Integration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Practical Integration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#complementary-systems" class="md-nav__link">
    <span class="md-ellipsis">
      Complementary Systems
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#concrete-comparative-example" class="md-nav__link">
    <span class="md-ellipsis">
      Concrete Comparative Example
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#system-limitations-and-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      System Limitations and Considerations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Conclusion">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-distinctions" class="md-nav__link">
    <span class="md-ellipsis">
      Key Distinctions
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unified-understanding" class="md-nav__link">
    <span class="md-ellipsis">
      Unified Understanding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#practical-integration" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Integration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="llm-weights-vs-vector-stores-knowledge-storage-and-similarity-calculations">LLM Weights vs Vector Stores: Knowledge Storage and Similarity Calculations<a class="headerlink" href="#llm-weights-vs-vector-stores-knowledge-storage-and-similarity-calculations" title="Permanent link">&para;</a></h1>
<h2 id="part-i-knowledge-storage-mechanisms">PART I: Knowledge Storage Mechanisms<a class="headerlink" href="#part-i-knowledge-storage-mechanisms" title="Permanent link">&para;</a></h2>
<h3 id="1-llm-weights">1. LLM Weights<a class="headerlink" href="#1-llm-weights" title="Permanent link">&para;</a></h3>
<h4 id="introduction-how-knowledge-becomes-internalized-in-llm-weights">Introduction: How Knowledge Becomes Internalized in LLM Weights<a class="headerlink" href="#introduction-how-knowledge-becomes-internalized-in-llm-weights" title="Permanent link">&para;</a></h4>
<p>Consider how humans internalize knowledge: when you learn that "Paris is the capital of France," this fact doesn't get stored in a single brain cell. Instead, it becomes encoded across neural connections that activate together when you think about Paris, France, or capitals. LLM weights work similarly - they store knowledge as <strong>learned patterns distributed across billions of parameters</strong>.</p>
<p><strong>Knowledge Internalization Process:</strong></p>
<ul>
<li><strong>Training Exposure</strong>: During training, the model encounters "Paris is the capital of France" in thousands of different contexts</li>
<li><strong>Statistical Learning</strong>: Weights learn that "Paris" and "capital of France" frequently co-occur and have semantic relationships</li>
<li><strong>Distributed Encoding</strong>: This knowledge becomes encoded across many weight matrices, not stored as discrete facts</li>
<li><strong>Pattern Activation</strong>: During inference, when asked about Paris, the learned weight patterns activate to generate contextually appropriate responses</li>
</ul>
<p>Unlike databases where "Paris → capital → France" might be a clear lookup table entry, LLMs internalize this as statistical associations that enable both recall and generalization to new contexts.</p>
<p><strong>Core Intuition</strong>: Think of LLM weights like a distributed neural architecture where:</p>
<ul>
<li><strong>Embedding weights</strong> position tokens in high-dimensional semantic space using vector representations (analogous to principal component analysis projections)</li>
<li><strong>Attention weights</strong> learn contextual dependencies between tokens using learned similarity functions</li>
<li><strong>Feed-forward weights</strong> perform non-linear feature transformations through learned basis functions and activations</li>
</ul>
<p>The magic happens when these three types of weights work together to generate contextual understanding.</p>
<h4 id="weight-computation-timeline-and-lifecycle">Weight Computation Timeline and Lifecycle<a class="headerlink" href="#weight-computation-timeline-and-lifecycle" title="Permanent link">&para;</a></h4>
<p><strong>The Journey of a Token Through Transformer Layers</strong></p>
<p>To understand how weights store knowledge, let's follow the word "cat" through a transformer model step-by-step.</p>
<p><strong>Step 1: From Text to Numbers (Tokenization and Embedding)</strong></p>
<p>First, we need to understand how text becomes numbers that neural networks can process:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>Text: &quot;cat&quot;
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>↓ Tokenization (convert text to numbers)
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>Token ID: 1247  (each word/subword gets a unique integer ID)
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>↓ Embedding Lookup (convert ID to vector)
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>Embedding vector: [0.8, 0.2, 0.1]  (learned position in semantic space)
</code></pre></div>
<p><strong>Important Note on Vector Dimensions:</strong>
Throughout this document, we use <strong>3-dimensional vectors</strong> like [0.8, 0.2, 0.1] for educational clarity. This is a <strong>simplified example</strong> to make the mathematics tractable and intuitive.</p>
<p><strong>Real-world embeddings are much larger:</strong></p>
<ul>
<li><strong>BERT-base</strong>: 768 dimensions</li>
<li><strong>GPT-3</strong>: 4,096 dimensions  </li>
<li><strong>GPT-4</strong>: 8,192+ dimensions</li>
</ul>
<p><strong>Why we use 3D examples:</strong></p>
<ol>
<li><strong>Mathematical clarity</strong>: Easy to follow dot products and matrix multiplications</li>
<li><strong>Visual intuition</strong>: Can conceptualize 3D space (length, width, height)</li>
<li><strong>Concrete calculations</strong>: All arithmetic is human-verifiable</li>
<li><strong>Pedagogical progression</strong>: Build understanding before introducing complexity</li>
</ol>
<p><strong>The principles remain identical at any scale</strong> - whether 3D or 768D, the attention mechanisms, similarity calculations, and weight interactions work exactly the same way.</p>
<p><strong>What is W_embed?</strong></p>
<ul>
<li><code>W_embed</code> is the <strong>embedding matrix</strong> with shape <code>[vocab_size, embedding_dim]</code></li>
<li>For a vocabulary of 50,000 words and 768-dimensional embeddings: <code>W_embed</code> is <code>[50000, 768]</code></li>
<li>Each row represents one word's position in semantic space</li>
<li><code>W_embed[1247]</code> gives us the embedding vector for token ID 1247 ("cat")</li>
</ul>
<p><strong>During Training Phase:</strong></p>
<ol>
<li><strong>Embedding Weight Learning:</strong>
   <div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>Input: Token &quot;cat&quot; (ID: 1247)
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>Lookup: embedding_vector = W_embed[1247] = [0.8, 0.2, 0.1]
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>How W_embed learns:
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>- Initially random: W_embed[1247] = [0.1, -0.3, 0.9] (random values)
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>- Through training: Gradually moves to [0.8, 0.2, 0.1] (learned optimal position)
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>- Goal: Similar words (cat, dog, animal) get similar vectors
</code></pre></div></li>
</ol>
<p>The exact values aren't meaningful individually. What matters is their <strong>relationships</strong>:</p>
<ul>
<li><code>cat=[0.8, 0.2, 0.1]</code> and <code>dog=[0.7, 0.3, 0.2]</code> are close (similar animals)</li>
<li>
<p><code>cat=[0.8, 0.2, 0.1]</code> and <code>house=[0.1, 0.8, 0.3]</code> are distant (different concepts)</p>
</li>
<li>
<p><strong>Attention Weight Computation: The Communication Protocol</strong></p>
</li>
</ul>
<p><strong>The Database Join Analogy: Understanding Query, Key, and Value</strong></p>
<p>Consider a distributed database system performing content-based joins. For each information request:</p>
<ul>
<li><strong>Query (Q):</strong> The search criteria or predicate (the current token's information requirements)</li>
<li><strong>Key (K):</strong> The indexed attributes or metadata (how other tokens advertise their content)</li>
<li><strong>Value (V):</strong> The actual data payload (the semantic information other tokens provide)</li>
</ul>
<p>The attention mechanism compares the Query to all Keys to decide which Values (information) are most relevant to the current word.</p>
<p><strong>Step-by-Step Attention Computation:</strong></p>
<p>Context: "The big cat runs"
   Current focus: "cat" wants to understand its context</p>
<p>Starting point: h_cat = [0.8, 0.2, 0.1] (3D embedding from previous layer)
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>   Step 1: Create the Question (Query Formation)
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>   Query creation: Q_cat = h_cat · W_q
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>   W_q = [[0.9, 0.1, 0.2],   ← learned &quot;question-forming&quot; weights
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>         [0.2, 0.8, 0.3],    ← each column learns different question patterns  
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>         [0.1, 0.3, 0.7]]    ← e.g., col1: &quot;animal properties&quot;, col2: &quot;size attributes&quot;, col3: &quot;location context&quot;
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>
<a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>   Q_cat = [0.8, 0.2, 0.1] · W_q = [0.77, 0.27, 0.29]
<a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>
<a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>   What is a &quot;Question Vector&quot;?
<a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>   Q_cat = [0.77, 0.27, 0.29] encodes &quot;cat&#39;s search intent&quot;:
<a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>
<a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>   - Dimension 0 (0.77): Strongly looking for &quot;animal properties&quot;  
<a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>   - Dimension 1 (0.27): Moderately looking for &quot;size attributes&quot;
<a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a>   - Dimension 2 (0.29): Moderately looking for &quot;location context&quot;
</code></pre></div></p>
<p><strong>Matrix Multiplication Details:</strong>
   Each column of W_q creates one dimension of the query vector:</p>
<ul>
<li>Q_cat[0] = 0.8×0.9 + 0.2×0.2 + 0.1×0.1 = 0.77 (column 1 → "animal properties")</li>
<li>Q_cat[1] = 0.8×0.1 + 0.2×0.8 + 0.1×0.3 = 0.27 (column 2 → "size attributes")  </li>
<li>Q_cat[2] = 0.8×0.2 + 0.2×0.3 + 0.1×0.7 = 0.29 (column 3 → "location context")</li>
</ul>
<p><strong>Analogy:</strong> Think of W_q columns as "question templates"—each column extracts a different aspect of the word's meaning to help the model decide what information to seek from other words.</p>
<p>In real models, both the input and output dimensions are much larger (e.g., 768 or 4096), but the principle is the same: the weight matrix transforms the input embedding into a query vector for attention.</p>
<p><strong>Why Question-Forming Matrix Matters:</strong>
   Different words need different types of questions:</p>
<ul>
<li>Nouns ask: "What describes me?" "What category am I?"</li>
<li>Verbs ask: "Who is my subject?" "What is my object?"</li>
<li>W_q learns these question patterns during training</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>Step 2: Create Advertisements (Key Formation)
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>For word &quot;animal&quot;: K_animal = h_animal · W_k
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>W_k = [[0.8, 0.2, 0.1],    ← learned &quot;advertisement-forming&quot; weights
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>       [0.3, 0.7, 0.4],    ← each column learns different ad strategies
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>       [0.2, 0.1, 0.8]]    ← e.g., col1: &quot;animal info&quot;, col2: &quot;size info&quot;, col3: &quot;location info&quot;
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>
<a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>K_animal = [0.7, 0.3, 0.2] · W_k = [0.8, 0.4, 0.1]
<a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>
<a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>What is &quot;Learned Advertisement&quot;?
<a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>K_animal = [0.8, 0.4, 0.1] encodes &quot;what animal offers&quot;:
<a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>
<a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>- Dimension 0 (0.8): &quot;I strongly provide animal properties&quot;
<a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>- Dimension 1 (0.4): &quot;I moderately provide size info&quot;  
<a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>- Dimension 2 (0.1): &quot;I weakly provide location context&quot;
<a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>
<a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>Perfect match! Cat asks [0.77, ?, ?] for animal properties, 
<a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>               Animal offers [0.8, ?, ?] animal properties
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>Step 3: Calculate Compatibility (Attention Scores)
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>Attention Score = Q_cat · K_animal 
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>                = [0.77, 0.27, 0.29] · [0.8, 0.4, 0.1] 
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>                = (0.77×0.8) + (0.27×0.4) + (0.29×0.1)
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>                = 0.616 + 0.108 + 0.029 = 0.753
<a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>
<a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>High score (0.753) means &quot;cat&#39;s question matches animal&#39;s advertisement well&quot;
<a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>
<a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>For all words:
<a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>Q_cat · K_the = [0.77, 0.27, 0.29] · [0.1, 0.2, 0.4] = 0.247
<a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>Q_cat · K_big = [0.77, 0.27, 0.29] · [0.2, 0.8, 0.1] = 0.399  
<a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>Q_cat · K_animal = [0.77, 0.27, 0.29] · [0.8, 0.4, 0.1] = 0.753
<a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>Q_cat · K_runs = [0.77, 0.27, 0.29] · [0.3, 0.2, 0.7] = 0.488
<a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>
<a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>Raw scores: [the: 0.247, big: 0.399, animal: 0.753, runs: 0.488]
</code></pre></div>
<p><strong>Why Softmax Here? (Creating Fair Attention Distribution)</strong>
   <div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>Problem: Raw scores [0.247, 0.399, 0.753, 0.488] don&#39;t sum to 1
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>Solution: Softmax converts to probabilities that sum to 1.0
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>
<a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>Softmax([0.247, 0.399, 0.753, 0.488]) = [0.20, 0.23, 0.33, 0.25]
<a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>
<a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>Interpretation: Cat pays attention to:
<a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>
<a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>- 33% to &quot;animal&quot; (highest compatibility)
<a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>- 25% to &quot;runs&quot; and 23% to &quot;big&quot; (moderate compatibility)  
<a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>- 20% to &quot;the&quot; (lowest compatibility)
</code></pre></div></p>
<ol>
<li><strong>Feed-Forward Weight Computation: Pattern Recognition and Refinement</strong></li>
</ol>
<p><strong>What happens after attention?</strong>
   After attention, "cat" now has a rich, context-aware representation that knows it's "big" and related to "animal". The feed-forward network (FFN) acts like a pattern recognition system that extracts and refines higher-level concepts.</p>
<p><strong>The Two-Stage Processing Pipeline:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>FFN(x) = W_2 · ReLU(W_1 · x + b_1) + b_2
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>Input: x = [0.75, 0.28, 0.15] (enriched cat representation after attention)
<a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>             │      │      │
<a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>             │      │      └── location context (from &quot;runs&quot;)
<a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>             │      └────────── size info (from &quot;big&quot;)  
<a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>             └───────────────── animal properties (from context)
<a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a>
<a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a>Stage 1: Pattern Detection (Expansion)
<a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a>z = W_1 · x + b_1 = [2048×768] · [0.75, 0.28, 0.15] + bias
<a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a>
<a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a>Why expand 768 → 2048 dimensions?
<a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a>
<a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a>- Creates space for detecting complex patterns
<a id="__codelineno-6-15" name="__codelineno-6-15" href="#__codelineno-6-15"></a>- Each of 2048 neurons can specialize in different concepts:
<a id="__codelineno-6-16" name="__codelineno-6-16" href="#__codelineno-6-16"></a>  * Neuron 42: &quot;large domestic animal&quot; pattern
<a id="__codelineno-6-17" name="__codelineno-6-17" href="#__codelineno-6-17"></a>  * Neuron 156: &quot;animal that moves&quot; pattern  
<a id="__codelineno-6-18" name="__codelineno-6-18" href="#__codelineno-6-18"></a>  * Neuron 891: &quot;pet in house context&quot; pattern
<a id="__codelineno-6-19" name="__codelineno-6-19" href="#__codelineno-6-19"></a>
<a id="__codelineno-6-20" name="__codelineno-6-20" href="#__codelineno-6-20"></a>z = [0.9, -0.3, 0.7, -0.1, 0.8, ..., 0.4] (2048 values)
<a id="__codelineno-6-21" name="__codelineno-6-21" href="#__codelineno-6-21"></a>     ↑     ↑     ↑     ↑     ↑         ↑
<a id="__codelineno-6-22" name="__codelineno-6-22" href="#__codelineno-6-22"></a>     │     │     │     │     │         └── pattern 2048
<a id="__codelineno-6-23" name="__codelineno-6-23" href="#__codelineno-6-23"></a>     │     │     │     │     └─────────────── &quot;domestic pet&quot; detected
<a id="__codelineno-6-24" name="__codelineno-6-24" href="#__codelineno-6-24"></a>     │     │     │     └───────────────────── irrelevant pattern
<a id="__codelineno-6-25" name="__codelineno-6-25" href="#__codelineno-6-25"></a>     │     │     └─────────────────────────── &quot;animal movement&quot; detected  
<a id="__codelineno-6-26" name="__codelineno-6-26" href="#__codelineno-6-26"></a>     │     └───────────────────────────────── irrelevant pattern
<a id="__codelineno-6-27" name="__codelineno-6-27" href="#__codelineno-6-27"></a>     └─────────────────────────────────────── &quot;large animal&quot; detected
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>Stage 2: Non-Linear Filtering (ReLU Activation)
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>activated = ReLU(z) = max(0, z)
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>What does &quot;non-linear transformation&quot; mean?
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>
<a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>- Linear: output is proportional to input (like multiplication)
<a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>- Non-linear: introduces decision boundaries and complex relationships
<a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>
<a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>ReLU in action:
<a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a>z =        [0.9, -0.3, 0.7, -0.1, 0.8, ..., 0.4]
<a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a>ReLU(z) =  [0.9,  0.0, 0.7,  0.0, 0.8, ..., 0.4]
<a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a>           ↑      ↑     ↑      ↑     ↑          ↑
<a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a>           │      │     │      │     │          └── kept
<a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a>           │      │     │      │     └─────────────── kept &quot;domestic pet&quot;
<a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a>           │      │     │      └───────────────────── removed (negative)
<a id="__codelineno-7-16" name="__codelineno-7-16" href="#__codelineno-7-16"></a>           │      │     └─────────────────────────── kept &quot;animal movement&quot;
<a id="__codelineno-7-17" name="__codelineno-7-17" href="#__codelineno-7-17"></a>           │      └───────────────────────────────── removed (negative)
<a id="__codelineno-7-18" name="__codelineno-7-18" href="#__codelineno-7-18"></a>           └─────────────────────────────────────── kept &quot;large animal&quot;
<a id="__codelineno-7-19" name="__codelineno-7-19" href="#__codelineno-7-19"></a>
<a id="__codelineno-7-20" name="__codelineno-7-20" href="#__codelineno-7-20"></a>Purpose: Only keep activated patterns, discard irrelevant ones
<a id="__codelineno-7-21" name="__codelineno-7-21" href="#__codelineno-7-21"></a>Effect: Sparse, selective feature representation
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>Stage 3: Pattern Synthesis (Compression back to 768D)
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>output = W_2 · activated + b_2 = [768×2048] · activated + bias
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>Final result: [0.83, 0.31, 0.22] (back to 768 dimensions)
<a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>               ↑     ↑     ↑
<a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>               │     │     └── refined location understanding
<a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>               │     └────────── enhanced size attribute  
<a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>               └──────────────── enriched animal concept
<a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>
<a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>Higher-Level Patterns Extracted:
<a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>
<a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>- &quot;Cat&quot; now understands it&#39;s a &quot;large domestic animal that moves&quot;
<a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>- More sophisticated than initial embedding
<a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>- Ready for next transformer layer or final prediction
</code></pre></div>
<p><strong>Why This Architecture? (The Power of Non-Linear Transformations)</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a>Linear vs Non-Linear Pattern Detection:
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>Linear transformation only:
<a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>&quot;big cat&quot; → [0.75, 0.28] → linear combo → limited patterns
<a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>
<a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>Non-linear (FFN) transformation:
<a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a>&quot;big cat&quot; → [0.75, 0.28] → expand → ReLU → compress → rich patterns
<a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>
<a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a>Examples of higher-level patterns FFN can detect:
<a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a>
<a id="__codelineno-9-11" name="__codelineno-9-11" href="#__codelineno-9-11"></a>- &quot;domestic AND large&quot; → house pet
<a id="__codelineno-9-12" name="__codelineno-9-12" href="#__codelineno-9-12"></a>- &quot;animal AND moves&quot; → living creature  
<a id="__codelineno-9-13" name="__codelineno-9-13" href="#__codelineno-9-13"></a>- &quot;pet AND big AND runs&quot; → dog-like characteristics
<a id="__codelineno-9-14" name="__codelineno-9-14" href="#__codelineno-9-14"></a>
<a id="__codelineno-9-15" name="__codelineno-9-15" href="#__codelineno-9-15"></a>Linear combinations alone cannot capture these complex logical relationships
</code></pre></div>
<p><strong>Why ReLU Here (Not Softmax)?</strong></p>
<ul>
<li><strong>ReLU</strong>: Used for <strong>feature transformation</strong> - binary decision (keep/discard features)</li>
<li><strong>Softmax</strong>: Used for <strong>probability distributions</strong> - when we need weights that sum to 1</li>
<li><strong>FFN goal</strong>: Refine and extract patterns, not create attention weights</li>
<li><strong>Sparsity</strong>: ReLU creates sparse activations (many zeros), making computation efficient</li>
</ul>
<p><strong>During Inference Phase: Deterministic Knowledge Retrieval</strong></p>
<p><strong>What does "deterministic weight application" mean?</strong></p>
<p>Think of inference like playing a recorded symphony - every note is predetermined, no improvisation:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>Inference vs Training Comparison:
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>Training Phase (Weights Change):
<a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>Input: &quot;The cat runs&quot; → Forward pass → Loss = 0.3 → Backprop → Update weights
<a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>Next batch: &quot;Dogs play&quot; → Forward pass → Loss = 0.25 → Backprop → Update weights
<a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a>[Weights constantly evolving to minimize loss]
<a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a>
<a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a>Inference Phase (Weights Frozen):
<a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a>Input: &quot;The cat runs&quot; → Forward pass → Output: &quot;in the park&quot; 
<a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a>Input: &quot;Dogs play&quot; → Forward pass → Output: &quot;with balls&quot;
<a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a>[Same weights, deterministic output for same input]
</code></pre></div>
<p><strong>Step-by-Step Deterministic Process:</strong></p>
<ol>
<li><strong>Weight Loading</strong>: Pre-trained 175B parameters loaded into GPU memory as frozen matrices</li>
<li><strong>Forward Computation</strong>: Exact same mathematical operations every time</li>
<li>W_embed[token_id] → always returns same embedding</li>
<li>Attention(Q,K,V) → same attention weights for same input</li>
<li>FFN(x) → same transformations applied</li>
<li><strong>Hidden State Flow</strong>: <code>token_id → embedding → layer_1 → ... → layer_96 → output</code></li>
</ol>
<p><strong>Why "Deterministic" Matters:</strong></p>
<ul>
<li>Same input always produces same output (reproducible)</li>
<li>No learning during inference (weights don't update)  </li>
<li>Knowledge retrieval is purely computational, not adaptive</li>
<li>Enables caching and optimization strategies</li>
</ul>
<h4 id="hidden-states-and-weight-interaction">Hidden States and Weight Interaction<a class="headerlink" href="#hidden-states-and-weight-interaction" title="Permanent link">&para;</a></h4>
<p><strong>What Are Hidden States?</strong></p>
<p>Think of hidden states as "evolving understanding" of each word as it passes through transformer layers. Like how your understanding of "bank" changes when you read "river bank" vs "savings bank", hidden states capture context-dependent meaning.</p>
<p><strong>The Complete Journey: From Static Embeddings to Rich Representations</strong></p>
<p>Let's trace how the word "cat" evolves through multiple transformer layers:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>Input Sentence: &quot;The big cat runs&quot;
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>Layer 0 (Initial Embeddings - Static Word Meanings):
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>h_the = [0.1, 0.9, 0.2]    (generic &quot;the&quot; embedding)
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>h_big = [0.6, 0.1, 0.8]    (generic &quot;big&quot; embedding)  
<a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>h_cat = [0.8, 0.2, 0.1]    (generic &quot;cat&quot; embedding)
<a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>h_runs = [0.3, 0.7, 0.4]   (generic &quot;runs&quot; embedding)
</code></pre></div>
<p>At this stage, each word has its basic dictionary meaning, with no context.</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>Layer 1 (After Self-Attention - Words Start Talking):
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>`h_cat&#39;` is the output of the attention mechanism for the token &quot;cat&quot;. This is calculated as a weighted sum of the **Value (V)** vectors of all tokens in the sequence.
</code></pre></div>
How it's computed:</p>
<ol>
<li>
<p><strong>Create Value vectors</strong>: First, each token's hidden state <code>h</code> is projected into a Value vector <code>v</code> using a learned weight matrix <code>W_v</code>.</p>
<ul>
<li><code>v_the = h_the · W_v</code></li>
<li><code>v_big = h_big · W_v</code></li>
<li><code>v_cat = h_cat · W_v</code></li>
<li><code>v_runs = h_runs · W_v</code>
These <code>v</code> vectors represent the information each token offers.</li>
</ul>
</li>
<li>
<p><strong>Compute attention weights</strong>: The model calculates attention weights (as shown previously) that determine how much "cat" should pay attention to every other token.</p>
<ul>
<li>Attention weights for "cat": <code>[the: 0.05, big: 0.35, cat: 0.40, runs: 0.20]</code></li>
</ul>
</li>
<li>
<p><strong>Calculate the weighted sum of Value vectors</strong>: The new representation for "cat", <code>h_cat'</code>, is the sum of all Value vectors in the sequence, weighted by their respective attention scores.
    <code>h_cat' = 0.05·v_the + 0.35·v_big + 0.40·v_cat + 0.20·v_runs</code></p>
</li>
</ol>
<p>This process mixes information from the entire sequence into each token's representation, guided by the learned attention patterns. The result is that <code>h_cat'</code> is no longer just the generic embedding for "cat", but a new vector that has absorbed context—it now "knows" it's a "big cat".</p>
<p>Now "cat" understands it's a "big cat" (not just any cat).</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>Layer 6 (Deep Understanding - Rich Contextual Meaning):
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>h_cat&#39;&#39; = [0.75, 0.28, 0.15]
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>Through 6 layers of processing:
<a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>
<a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>- &quot;Cat&quot; now knows it&#39;s the subject of the sentence
<a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a>- It understands it&#39;s &quot;big&quot; (size attribute)
<a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a>- It anticipates &quot;runs&quot; (the action it performs)
<a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a>- It has absorbed semantic relationships from training data
</code></pre></div>
<p><strong>How Knowledge Emerges</strong></p>
<p>The relationship "cats are animals" emerges through this multi-layer process:</p>
<ol>
<li><strong>Embedding Layer</strong>: Positions "cat" and "animal" in similar regions of semantic space through learned linear transformations</li>
<li><strong>Attention Layers</strong>: Learn contextual dependencies where "cat" tokens develop strong attention patterns with "animal" tokens through self-supervised learning</li>
<li><strong>Feed-Forward Layers</strong>: Extract hierarchical taxonomic relationships (cat ⊂ mammal ⊂ animal) through non-linear feature combinations</li>
<li><strong>Output Layer</strong>: High logit values for "animal" when predicting after "The cat is an ___" through learned classification weights</li>
</ol>
<p><strong>The Distributed Knowledge Pattern</strong>:</p>
<ul>
<li>No single weight stores "cats are animals"</li>
<li>The relationship emerges from the collective behavior of millions of weights</li>
<li>Knowledge is implicit in the learned transformations, not explicit storage</li>
</ul>
<h4 id="multi-head-attention-why-multiple-perspectives-matter">Multi-Head Attention: Why Multiple Perspectives Matter<a class="headerlink" href="#multi-head-attention-why-multiple-perspectives-matter" title="Permanent link">&para;</a></h4>
<p><strong>The Problem with Single Attention</strong></p>
<p>Imagine trying to understand "The big cat runs fast" with only one type of question. You might focus on:</p>
<ul>
<li>ONLY grammar: "cat" relates to "runs" (subject-verb)</li>
<li>ONLY meaning: "cat" relates to "animal" (semantic category)  </li>
<li>ONLY modifiers: "big" relates to "cat" (adjective-noun)</li>
</ul>
<p>But you need ALL these relationships simultaneously!</p>
<p><strong>Multi-Head Solution: Parallel Attention Specialists</strong></p>
<p>Think of multi-head attention like having multiple specialists analyze the same sentence:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>Single Head Attention (Limited):
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>&quot;The big cat runs fast&quot;
<a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a>One attention pattern: cat → runs (subject-verb only)
<a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a>Missing: size relationship, semantic category, speed modifier
<a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a>
<a id="__codelineno-14-6" name="__codelineno-14-6" href="#__codelineno-14-6"></a>Multi-Head Attention (Comprehensive):
<a id="__codelineno-14-7" name="__codelineno-14-7" href="#__codelineno-14-7"></a>&quot;The big cat runs fast&quot;
<a id="__codelineno-14-8" name="__codelineno-14-8" href="#__codelineno-14-8"></a>Head 1: cat ↔ runs (grammar specialist)
<a id="__codelineno-14-9" name="__codelineno-14-9" href="#__codelineno-14-9"></a>Head 2: big ↔ cat (modifier specialist)  
<a id="__codelineno-14-10" name="__codelineno-14-10" href="#__codelineno-14-10"></a>Head 3: cat ↔ animal_concepts (semantic specialist)
<a id="__codelineno-14-11" name="__codelineno-14-11" href="#__codelineno-14-11"></a>Head 4: fast ↔ runs (adverb specialist)
</code></pre></div>
<p><strong>Gentle Introduction: From 1 Head to 12 Heads</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>Step 1: Understanding the Architecture
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>d_model = 768 (total representation size)
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>num_heads = 12 (number of parallel attention mechanisms)
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a>d_head = 768/12 = 64 (each head gets 64 dimensions)
<a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a>
<a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a>Step 2: Weight Matrix Organization
<a id="__codelineno-15-7" name="__codelineno-15-7" href="#__codelineno-15-7"></a>Instead of one big W_q [768×768], we have:
<a id="__codelineno-15-8" name="__codelineno-15-8" href="#__codelineno-15-8"></a>W_q split into 12 pieces: [768×64] each
<a id="__codelineno-15-9" name="__codelineno-15-9" href="#__codelineno-15-9"></a>W_k split into 12 pieces: [768×64] each  
<a id="__codelineno-15-10" name="__codelineno-15-10" href="#__codelineno-15-10"></a>W_v split into 12 pieces: [768×64] each
<a id="__codelineno-15-11" name="__codelineno-15-11" href="#__codelineno-15-11"></a>
<a id="__codelineno-15-12" name="__codelineno-15-12" href="#__codelineno-15-12"></a>Total parameters: same as single head, but organized differently
</code></pre></div>
<p><strong>Intuitive Head Specialization Example:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>Context: &quot;The big brown cat runs quickly&quot;
<a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a>
<a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a>Head 1: Grammar Specialist (Subject-Verb-Object patterns)
<a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a>Q_cat = [0.9, 0.1, 0.3, ..., 0.2] (64-dim)
<a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a>K_runs = [0.8, 0.2, 0.1, ..., 0.4] (64-dim)
<a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a>High attention: cat ↔ runs (subject-verb)
<a id="__codelineno-16-7" name="__codelineno-16-7" href="#__codelineno-16-7"></a>
<a id="__codelineno-16-8" name="__codelineno-16-8" href="#__codelineno-16-8"></a>Head 2: Adjective Specialist (Descriptive relationships)  
<a id="__codelineno-16-9" name="__codelineno-16-9" href="#__codelineno-16-9"></a>Q_cat = [0.2, 0.8, 0.6, ..., 0.1] (64-dim)
<a id="__codelineno-16-10" name="__codelineno-16-10" href="#__codelineno-16-10"></a>K_big = [0.3, 0.9, 0.7, ..., 0.2] (64-dim)
<a id="__codelineno-16-11" name="__codelineno-16-11" href="#__codelineno-16-11"></a>K_brown = [0.1, 0.8, 0.8, ..., 0.3] (64-dim)
<a id="__codelineno-16-12" name="__codelineno-16-12" href="#__codelineno-16-12"></a>High attention: cat ↔ big, cat ↔ brown
<a id="__codelineno-16-13" name="__codelineno-16-13" href="#__codelineno-16-13"></a>
<a id="__codelineno-16-14" name="__codelineno-16-14" href="#__codelineno-16-14"></a>Head 3: Semantic Specialist (Category relationships)
<a id="__codelineno-16-15" name="__codelineno-16-15" href="#__codelineno-16-15"></a>Q_cat = [0.8, 0.2, 0.1, ..., 0.9] (64-dim)  
<a id="__codelineno-16-16" name="__codelineno-16-16" href="#__codelineno-16-16"></a>K_animal_context = [0.7, 0.3, 0.2, ..., 0.8] (64-dim)
<a id="__codelineno-16-17" name="__codelineno-16-17" href="#__codelineno-16-17"></a>High attention: cat ↔ animal_concepts
<a id="__codelineno-16-18" name="__codelineno-16-18" href="#__codelineno-16-18"></a>
<a id="__codelineno-16-19" name="__codelineno-16-19" href="#__codelineno-16-19"></a>Head 4: Action-Modifier Specialist
<a id="__codelineno-16-20" name="__codelineno-16-20" href="#__codelineno-16-20"></a>Q_runs = [0.4, 0.1, 0.8, ..., 0.6] (64-dim)
<a id="__codelineno-16-21" name="__codelineno-16-21" href="#__codelineno-16-21"></a>K_quickly = [0.5, 0.2, 0.9, ..., 0.7] (64-dim)  
<a id="__codelineno-16-22" name="__codelineno-16-22" href="#__codelineno-16-22"></a>High attention: runs ↔ quickly
</code></pre></div>
<p><strong>How Heads Combine: The Integration Magic</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>After parallel processing:
<a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a>Head 1 output: [0.9, 0.2, 0.1, ..., 0.3] (cat with grammar info)
<a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a>Head 2 output: [0.1, 0.8, 0.6, ..., 0.2] (cat with size/color info)
<a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a>Head 3 output: [0.7, 0.1, 0.2, ..., 0.8] (cat with semantic info)
<a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a>...
<a id="__codelineno-17-6" name="__codelineno-17-6" href="#__codelineno-17-6"></a>Head 12 output: [0.3, 0.5, 0.4, ..., 0.6] (cat with other info)
<a id="__codelineno-17-7" name="__codelineno-17-7" href="#__codelineno-17-7"></a>
<a id="__codelineno-17-8" name="__codelineno-17-8" href="#__codelineno-17-8"></a>Concatenation: [Head1 | Head2 | Head3 | ... | Head12] 
<a id="__codelineno-17-9" name="__codelineno-17-9" href="#__codelineno-17-9"></a>Result: [64 + 64 + 64 + ... + 64] = 768-dimensional representation
<a id="__codelineno-17-10" name="__codelineno-17-10" href="#__codelineno-17-10"></a>
<a id="__codelineno-17-11" name="__codelineno-17-11" href="#__codelineno-17-11"></a>Final &quot;cat&quot; representation now contains:
<a id="__codelineno-17-12" name="__codelineno-17-12" href="#__codelineno-17-12"></a>
<a id="__codelineno-17-13" name="__codelineno-17-13" href="#__codelineno-17-13"></a>- Grammar role (subject of &quot;runs&quot;)  
<a id="__codelineno-17-14" name="__codelineno-17-14" href="#__codelineno-17-14"></a>- Physical attributes (big, brown)
<a id="__codelineno-17-15" name="__codelineno-17-15" href="#__codelineno-17-15"></a>- Semantic category (animal)
<a id="__codelineno-17-16" name="__codelineno-17-16" href="#__codelineno-17-16"></a>- Action context (runs quickly)
</code></pre></div>
<p><strong>Why This Architecture Works So Well:</strong></p>
<ol>
<li><strong>Specialization</strong>: Each head learns different types of relationships</li>
<li><strong>Parallel Processing</strong>: All relationships computed simultaneously  </li>
<li><strong>Complementary Views</strong>: Different heads capture different aspects</li>
<li><strong>Rich Integration</strong>: Final representation combines all perspectives</li>
</ol>
<p><strong>Multi-Head Attention Summary:</strong></p>
<table>
<thead>
<tr>
<th>Head Type</th>
<th>Specialization</th>
<th>Example Relationships</th>
<th>Why Important</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Grammar Heads (1,5)</strong></td>
<td>Subject-verb-object patterns</td>
<td>cat ↔ runs, animal ↔ is</td>
<td>Syntactic understanding</td>
</tr>
<tr>
<td><strong>Modifier Heads (2,4)</strong></td>
<td>Adjective-noun relationships</td>
<td>big ↔ cat, small ↔ pet</td>
<td>Descriptive attributes</td>
</tr>
<tr>
<td><strong>Semantic Heads (3,7,11)</strong></td>
<td>Category hierarchies</td>
<td>cat ↔ animal, pet ↔ domestic</td>
<td>Conceptual relationships</td>
</tr>
<tr>
<td><strong>Position Heads (6,8)</strong></td>
<td>Sequential dependencies</td>
<td>nearby words, sentence structure</td>
<td>Word order importance</td>
</tr>
</tbody>
</table>
<p><strong>Why Concatenation Matters:</strong> Each head contributes specialized knowledge (64 dimensions each), and concatenating all 12 heads (12×64=768) creates a rich representation that combines grammatical, semantic, and positional understanding.</p>
<p><strong>Knowledge Encoding Patterns:</strong>
The relationship "cats are animals" emerges through distributed processing:</p>
<ul>
<li><strong>Semantic heads</strong>: Learn hierarchical category relationships (cat→animal)</li>
<li><strong>Grammar heads</strong>: Learn syntactic patterns ("cat is", "animal that")</li>
<li><strong>Modifier heads</strong>: Learn contextual associations (pets, domestic, wild)</li>
<li><strong>FFN layers</strong>: Integrate these multi-head insights into refined understanding</li>
</ul>
<h4 id="understanding-scale-what-does-billion-parameters-actually-mean">Understanding Scale: What Does "Billion Parameters" Actually Mean?<a class="headerlink" href="#understanding-scale-what-does-billion-parameters-actually-mean" title="Permanent link">&para;</a></h4>
<p>Now that we understand how individual weights work, let's examine the scale at which modern LLMs operate.</p>
<p>Think of parameters as the learned coefficients in a massive system of linear equations. Each parameter represents a weight in the network's computational graph that determines how information propagates through the model's layers during inference.</p>
<p><strong>Concrete Example - GPT-3.5 (~175 billion parameters):</strong>
<em>Note: Parameter counts are illustrative approximations based on publicly available specifications.</em></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a>Embedding Layer:
<a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a>
<a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a>- Vocabulary: 50,000 tokens
<a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a>- Embedding size: 12,288 dimensions (actual GPT-3.5 size)
<a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a>- Parameters: 50,000 × 12,288 = 614.4 million
<a id="__codelineno-18-6" name="__codelineno-18-6" href="#__codelineno-18-6"></a>
<a id="__codelineno-18-7" name="__codelineno-18-7" href="#__codelineno-18-7"></a>96 Transformer Layers × Weight Matrices per layer:
<a id="__codelineno-18-8" name="__codelineno-18-8" href="#__codelineno-18-8"></a>
<a id="__codelineno-18-9" name="__codelineno-18-9" href="#__codelineno-18-9"></a>- Attention matrices (Q,K,V,O): 4 × (12,288 × 12,288) = 603.9 million per layer
<a id="__codelineno-18-10" name="__codelineno-18-10" href="#__codelineno-18-10"></a>- Feed-forward matrices (W1,W2): (12,288 × 49,152) + (49,152 × 12,288) = 1.2 billion per layer
<a id="__codelineno-18-11" name="__codelineno-18-11" href="#__codelineno-18-11"></a>- Layer normalization: 2 × 12,288 = 24,576 parameters per layer
<a id="__codelineno-18-12" name="__codelineno-18-12" href="#__codelineno-18-12"></a>- Per layer total: ~1.8 billion parameters
<a id="__codelineno-18-13" name="__codelineno-18-13" href="#__codelineno-18-13"></a>- All layers: 96 × 1.8B = 172.8 billion
<a id="__codelineno-18-14" name="__codelineno-18-14" href="#__codelineno-18-14"></a>
<a id="__codelineno-18-15" name="__codelineno-18-15" href="#__codelineno-18-15"></a>Output Layer:
<a id="__codelineno-18-16" name="__codelineno-18-16" href="#__codelineno-18-16"></a>
<a id="__codelineno-18-17" name="__codelineno-18-17" href="#__codelineno-18-17"></a>- Linear projection: 12,288 × 50,000 = 614.4 million
<a id="__codelineno-18-18" name="__codelineno-18-18" href="#__codelineno-18-18"></a>- Layer normalization: 12,288 parameters
<a id="__codelineno-18-19" name="__codelineno-18-19" href="#__codelineno-18-19"></a>
<a id="__codelineno-18-20" name="__codelineno-18-20" href="#__codelineno-18-20"></a>Total Core Parameters: 614M + 173B + 614M ≈ 175 billion
<a id="__codelineno-18-21" name="__codelineno-18-21" href="#__codelineno-18-21"></a>Remaining ~1B parameters: Position embeddings, additional biases, etc.
<a id="__codelineno-18-22" name="__codelineno-18-22" href="#__codelineno-18-22"></a>
<a id="__codelineno-18-23" name="__codelineno-18-23" href="#__codelineno-18-23"></a>Storage Requirements:
<a id="__codelineno-18-24" name="__codelineno-18-24" href="#__codelineno-18-24"></a>
<a id="__codelineno-18-25" name="__codelineno-18-25" href="#__codelineno-18-25"></a>- 175 billion parameters × 4 bytes/float = 700 GB of raw weights
<a id="__codelineno-18-26" name="__codelineno-18-26" href="#__codelineno-18-26"></a>- Why expensive GPU memory is crucial for inference
</code></pre></div>
<p><strong>Scale Perspective:</strong></p>
<ul>
<li><strong>1 million parameters</strong>: Small research model, basic pattern recognition</li>
<li><strong>100 million</strong>: BERT-base, practical applications, good language understanding  </li>
<li><strong>1 billion</strong>: GPT-2, moderate reasoning capability, coherent text generation</li>
<li><strong>100+ billion</strong>: GPT-3/4, ChatGPT, strong reasoning, complex problem solving</li>
<li><strong>1 trillion+</strong>: Cutting-edge research models, approaching human-level performance</li>
</ul>
<p><strong>Critical Insight</strong>: Each parameter stores a tiny piece of learned knowledge - no single parameter understands "cats are animals", but collectively they encode this relationship through the distributed weight patterns we've explored above.</p>
<h3 id="2-vector-store-knowledge-storage">2. Vector Store Knowledge Storage<a class="headerlink" href="#2-vector-store-knowledge-storage" title="Permanent link">&para;</a></h3>
<h4 id="introduction-what-are-vector-stores">Introduction: What Are Vector Stores?<a class="headerlink" href="#introduction-what-are-vector-stores" title="Permanent link">&para;</a></h4>
<p>Consider a high-dimensional content-addressable memory system where instead of organizing documents by hierarchical taxonomies, each document is positioned based on its learned semantic representation - a dense numerical encoding capturing its conceptual relationships. Vector databases work exactly this way: they store knowledge as <strong>discrete embeddings</strong> (high-dimensional numerical vectors) that can be efficiently retrieved through approximate nearest neighbor search.</p>
<p><strong>Core Intuition</strong>: Think of vector stores like:</p>
<ul>
<li><strong>A multidimensional indexing system</strong>: Every piece of text gets coordinates in learned semantic space using embedding functions</li>
<li><strong>An approximate nearest neighbor engine</strong>: Find documents with high cosine similarity to query vectors in sublinear time</li>
<li><strong>Explicit knowledge representation</strong>: Unlike LLMs, knowledge is stored as retrievable dense vectors rather than distributed weight patterns</li>
</ul>
<p><strong>Key Difference from LLMs</strong>: While LLMs encode knowledge implicitly in weight patterns, vector stores maintain explicit, searchable representations of facts and documents.</p>
<h4 id="how-vector-search-works-from-simple-to-sophisticated">How Vector Search Works: From Simple to Sophisticated<a class="headerlink" href="#how-vector-search-works-from-simple-to-sophisticated" title="Permanent link">&para;</a></h4>
<p><strong>The Fundamental Challenge</strong></p>
<p>Given a query like "What animals make good pets?", how do we find relevant documents from millions of stored vectors? This is the core challenge vector databases solve.</p>
<h4 id="vector-indexing-methods">Vector Indexing Methods<a class="headerlink" href="#vector-indexing-methods" title="Permanent link">&para;</a></h4>
<p>Understanding how vector databases achieve fast similarity search at scale requires examining different indexing strategies. Each method represents a different trade-off between speed, accuracy, and memory usage.</p>
<p><strong>Method 1: Brute Force Search (The Simple Approach)</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a>Problem: Find documents similar to query &quot;What animals are pets?&quot;
<a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a>
<a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a>Step 1: Convert query to vector
<a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a>query_vec = embedding_model(&quot;What animals are pets?&quot;) = [0.72, 0.31, 0.18]
<a id="__codelineno-19-5" name="__codelineno-19-5" href="#__codelineno-19-5"></a>
<a id="__codelineno-19-6" name="__codelineno-19-6" href="#__codelineno-19-6"></a>Step 2: Compare against ALL stored documents
<a id="__codelineno-19-7" name="__codelineno-19-7" href="#__codelineno-19-7"></a>doc1: &quot;Cats are popular pets&quot; → vector: [0.82, 0.31, 0.15]
<a id="__codelineno-19-8" name="__codelineno-19-8" href="#__codelineno-19-8"></a>doc2: &quot;Dogs make loyal companions&quot; → vector: [0.79, 0.33, 0.18]  
<a id="__codelineno-19-9" name="__codelineno-19-9" href="#__codelineno-19-9"></a>doc3: &quot;Houses need maintenance&quot; → vector: [0.12, 0.85, 0.43]
<a id="__codelineno-19-10" name="__codelineno-19-10" href="#__codelineno-19-10"></a>
<a id="__codelineno-19-11" name="__codelineno-19-11" href="#__codelineno-19-11"></a>Step 3: Calculate similarities
<a id="__codelineno-19-12" name="__codelineno-19-12" href="#__codelineno-19-12"></a>similarity(query, doc1) = cosine([0.72, 0.31, 0.18], [0.82, 0.31, 0.15]) = 0.94
<a id="__codelineno-19-13" name="__codelineno-19-13" href="#__codelineno-19-13"></a>similarity(query, doc2) = cosine([0.72, 0.31, 0.18], [0.79, 0.33, 0.18]) = 0.96
<a id="__codelineno-19-14" name="__codelineno-19-14" href="#__codelineno-19-14"></a>similarity(query, doc3) = cosine([0.72, 0.31, 0.18], [0.12, 0.85, 0.43]) = 0.32
<a id="__codelineno-19-15" name="__codelineno-19-15" href="#__codelineno-19-15"></a>
<a id="__codelineno-19-16" name="__codelineno-19-16" href="#__codelineno-19-16"></a>Step 4: Rank results
<a id="__codelineno-19-17" name="__codelineno-19-17" href="#__codelineno-19-17"></a>
<a id="__codelineno-19-18" name="__codelineno-19-18" href="#__codelineno-19-18"></a>1. doc2 (similarity: 0.96) - &quot;Dogs make loyal companions&quot;
<a id="__codelineno-19-19" name="__codelineno-19-19" href="#__codelineno-19-19"></a>2. doc1 (similarity: 0.94) - &quot;Cats are popular pets&quot;  
<a id="__codelineno-19-20" name="__codelineno-19-20" href="#__codelineno-19-20"></a>3. doc3 (similarity: 0.32) - &quot;Houses need maintenance&quot;
<a id="__codelineno-19-21" name="__codelineno-19-21" href="#__codelineno-19-21"></a>
<a id="__codelineno-19-22" name="__codelineno-19-22" href="#__codelineno-19-22"></a>Complexity: O(n·d) where n=documents, d=dimensions
</code></pre></div>
<p><strong>Mathematical Problem</strong>: For n documents with d-dimensional vectors:</p>
<ul>
<li><strong>Time complexity</strong>: O(n·d) - we compute d multiplications for each of n documents</li>
<li><strong>Example</strong>: 100M documents × 768 dimensions = 76.8 billion operations per query</li>
<li><strong>Reality check</strong>: At 1 billion ops/second, that's 77 seconds per search!</li>
</ul>
<p>The solution: <strong>Approximate Nearest Neighbor (ANN)</strong> methods that trade a small amount of accuracy for massive speed improvements.</p>
<p><strong>Method 2: HNSW - The Highway System for Vectors</strong></p>
<p><strong>The Elevator Building Analogy:</strong> Think of HNSW (Hierarchical Navigable Small World) like navigating a tall building with multiple elevator systems:</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a>Analogy: Finding someone in a large office building
<a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a>
<a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a>- Level 2 (Express elevators): Connect to major floors only [Floor 1 ←→ Floor 20 ←→ Floor 40]
<a id="__codelineno-20-4" name="__codelineno-20-4" href="#__codelineno-20-4"></a>- Level 1 (Local elevators): Connect floors within sections [Floor 18 ←→ Floor 19 ←→ Floor 20]  
<a id="__codelineno-20-5" name="__codelineno-20-5" href="#__codelineno-20-5"></a>- Level 0 (Walking): Connect every adjacent room on the same floor
<a id="__codelineno-20-6" name="__codelineno-20-6" href="#__codelineno-20-6"></a>
<a id="__codelineno-20-7" name="__codelineno-20-7" href="#__codelineno-20-7"></a>HNSW Vector Index:
<a id="__codelineno-20-8" name="__codelineno-20-8" href="#__codelineno-20-8"></a>Level 2: [doc1] ←→ [doc5] ←→ [doc12]  (sparse, long-distance connections)
<a id="__codelineno-20-9" name="__codelineno-20-9" href="#__codelineno-20-9"></a>Level 1: [doc1] ←→ [doc2] ←→ [doc5] ←→ [doc8] ←→ [doc12] (medium connections)
<a id="__codelineno-20-10" name="__codelineno-20-10" href="#__codelineno-20-10"></a>Level 0: [doc1] ←→ [doc2] ←→ [doc3] ←→ [doc4] ←→ [doc5] ←→ ... (dense, local connections)
</code></pre></div>
<strong>Mathematical Foundation:</strong></p>
<ul>
<li><strong>Time complexity</strong>: O(log n) on average</li>
<li><strong>Space complexity</strong>: O(n·M) where M is average connections per node</li>
<li><strong>Search algorithm</strong>: Greedy search through hierarchical graph layers</li>
</ul>
<p><strong>Search Process:</strong></p>
<ol>
<li>Start at Level 2, find closest document to query</li>
<li>Navigate to similar documents at this level</li>
<li>Drop down to Level 1, continue navigation  </li>
<li>Drop to Level 0, find final closest matches</li>
</ol>
<p><strong>Performance Math</strong>: </p>
<ul>
<li>Brute force: 100M comparisons for 100M documents</li>
<li>HNSW: ~27 comparisons (log₂(100M) ≈ 27)</li>
<li><strong>Speedup</strong>: 3.7 million times faster!</li>
</ul>
<p><strong>Hands-on Implementation:</strong></p>
<blockquote>
<p>📓 <strong>Interactive Tutorial:</strong> See HNSW in action with executable Python code in <a href="../pynb/vector_search/vector_search.ipynb">pynb/vector_search/vector_search.ipynb</a></p>
<p>The notebook demonstrates:
- Building HNSW index with customizable parameters (M, ef_construction)
- Performance comparisons with timing benchmarks
- Recall vs speed trade-offs with real data
- Parameter tuning effects on search quality</p>
</blockquote>
<p><strong>Method 3: IVF - The Clustering Approach</strong></p>
<p><strong>The Filing Cabinet Analogy:</strong> Think of IVF (Inverted File) like organizing documents in labeled filing cabinets:</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a>Office Filing System:
<a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a>Cabinet_1 (Animal Research): [Doc1, Doc2, Doc3, ...]
<a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a>Cabinet_2 (Computer Science): [Doc10, Doc11, Doc12, ...] 
<a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a>Cabinet_3 (History Papers): [Doc20, Doc21, Doc22, ...]
<a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a>
<a id="__codelineno-21-6" name="__codelineno-21-6" href="#__codelineno-21-6"></a>Vector Database Clustering:
<a id="__codelineno-21-7" name="__codelineno-21-7" href="#__codelineno-21-7"></a>Cluster 1 (Animal docs): centroid = [0.8, 0.2, 0.1]
<a id="__codelineno-21-8" name="__codelineno-21-8" href="#__codelineno-21-8"></a>├── &quot;Cats are pets&quot; → [0.82, 0.31, 0.15]
<a id="__codelineno-21-9" name="__codelineno-21-9" href="#__codelineno-21-9"></a>├── &quot;Dogs love running&quot; → [0.79, 0.33, 0.18]  
<a id="__codelineno-21-10" name="__codelineno-21-10" href="#__codelineno-21-10"></a>└── &quot;Small pets need care&quot; → [0.75, 0.35, 0.22]
<a id="__codelineno-21-11" name="__codelineno-21-11" href="#__codelineno-21-11"></a>
<a id="__codelineno-21-12" name="__codelineno-21-12" href="#__codelineno-21-12"></a>Cluster 2 (House docs): centroid = [0.1, 0.8, 0.3]
<a id="__codelineno-21-13" name="__codelineno-21-13" href="#__codelineno-21-13"></a>├── &quot;Big house in park&quot; → [0.12, 0.85, 0.43]
<a id="__codelineno-21-14" name="__codelineno-21-14" href="#__codelineno-21-14"></a>└── &quot;House needs cleaning&quot; → [0.08, 0.78, 0.35]
</code></pre></div>
<strong>Mathematical Foundation:</strong></p>
<ul>
<li><strong>Time complexity</strong>: O(n/k + k) where k = number of clusters</li>
<li><strong>Space complexity</strong>: O(n + k·d) for storing documents and centroids</li>
<li><strong>Optimal k</strong>: Usually √n clusters (e.g., 1000 clusters for 1M documents)</li>
</ul>
<p><strong>Search Process:</strong></p>
<ol>
<li>Query: "What animals are pets?" → [0.72, 0.31, 0.18]</li>
<li>Find closest cluster centroid → Cluster 1 (animals)</li>
<li>Search only within Cluster 1 → much faster!</li>
<li>Reduced search: 3 documents instead of 5 total</li>
</ol>
<p><strong>Performance Math:</strong></p>
<ul>
<li><strong>1M documents, 1000 clusters</strong>: Search 1000 docs instead of 1M</li>
<li><strong>Speedup</strong>: 1000× faster than brute force</li>
<li><strong>Trade-off</strong>: Might miss documents in wrong clusters (~2-5% recall loss)</li>
</ul>
<p><strong>Hands-on Implementation:</strong></p>
<blockquote>
<p>📓 <strong>Interactive Tutorial:</strong> Experience IVF clustering with executable Python code in <a href="../pynb/vector_search/vector_search.ipynb">pynb/vector_search/vector_search.ipynb</a></p>
<p>The notebook demonstrates:
- Building IVF index with k-means clustering
- Effect of cluster count (nlist) on performance
- Search probe tuning (nprobes) for accuracy vs speed
- Cluster distribution analysis and optimization</p>
</blockquote>
<p><strong>Method 4: Product Quantization - The Compression Master</strong></p>
<p><strong>The Color Palette Analogy:</strong> Think of quantization like converting a detailed photograph to use only a limited set of colors, like the 16-color palette on old video games. Instead of millions of possible colors, you pick the closest match from your small palette, making the image much smaller to store while keeping it recognizable.</p>
<p>PQ is like creating a "summary" of each vector to save memory:</p>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a>Real-World Memory Problem:
<a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a>1 million documents × 768 dimensions × 32 bits/float = 24.6 GB RAM
<a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a>→ Too expensive for production systems!
<a id="__codelineno-22-4" name="__codelineno-22-4" href="#__codelineno-22-4"></a>
<a id="__codelineno-22-5" name="__codelineno-22-5" href="#__codelineno-22-5"></a>Solution: Compress vectors while preserving similarity relationships
<a id="__codelineno-22-6" name="__codelineno-22-6" href="#__codelineno-22-6"></a>
<a id="__codelineno-22-7" name="__codelineno-22-7" href="#__codelineno-22-7"></a>Original vector (768 dimensions): [0.82, 0.31, 0.15, 0.67, 0.23, ..., 0.44]
<a id="__codelineno-22-8" name="__codelineno-22-8" href="#__codelineno-22-8"></a>                                  │  96 dims  │  96 dims  │ ... │  96 dims  │
<a id="__codelineno-22-9" name="__codelineno-22-9" href="#__codelineno-22-9"></a>                                  └─ chunk 1 ──┴─ chunk 2 ──┴─────┴─ chunk 8 ─┘
<a id="__codelineno-22-10" name="__codelineno-22-10" href="#__codelineno-22-10"></a>
<a id="__codelineno-22-11" name="__codelineno-22-11" href="#__codelineno-22-11"></a>Step 1: Split into 8 chunks of 96 dimensions each
<a id="__codelineno-22-12" name="__codelineno-22-12" href="#__codelineno-22-12"></a>chunk_1 = [0.82, 0.31, 0.15, ...]  (96 float numbers)
<a id="__codelineno-22-13" name="__codelineno-22-13" href="#__codelineno-22-13"></a>chunk_2 = [0.67, 0.23, 0.44, ...]  (96 float numbers)
<a id="__codelineno-22-14" name="__codelineno-22-14" href="#__codelineno-22-14"></a>...
<a id="__codelineno-22-15" name="__codelineno-22-15" href="#__codelineno-22-15"></a>chunk_8 = [0.33, 0.78, 0.12, ...]  (96 float numbers)
<a id="__codelineno-22-16" name="__codelineno-22-16" href="#__codelineno-22-16"></a>
<a id="__codelineno-22-17" name="__codelineno-22-17" href="#__codelineno-22-17"></a>Step 2: Learn 256 &quot;prototype&quot; chunks for each position (like a codebook)
<a id="__codelineno-22-18" name="__codelineno-22-18" href="#__codelineno-22-18"></a>Training creates centroids: centroid_0, centroid_1, ..., centroid_255
<a id="__codelineno-22-19" name="__codelineno-22-19" href="#__codelineno-22-19"></a>Each centroid represents a &quot;typical&quot; pattern for that chunk position
<a id="__codelineno-22-20" name="__codelineno-22-20" href="#__codelineno-22-20"></a>
<a id="__codelineno-22-21" name="__codelineno-22-21" href="#__codelineno-22-21"></a>Step 3: Replace each chunk with its closest prototype ID
<a id="__codelineno-22-22" name="__codelineno-22-22" href="#__codelineno-22-22"></a>chunk_1 closest to centroid_42 → store ID: 42 (1 byte instead of 96×4 bytes)
<a id="__codelineno-22-23" name="__codelineno-22-23" href="#__codelineno-22-23"></a>chunk_2 closest to centroid_156 → store ID: 156 (1 byte)
<a id="__codelineno-22-24" name="__codelineno-22-24" href="#__codelineno-22-24"></a>...
<a id="__codelineno-22-25" name="__codelineno-22-25" href="#__codelineno-22-25"></a>chunk_8 closest to centroid_73 → store ID: 73 (1 byte)
<a id="__codelineno-22-26" name="__codelineno-22-26" href="#__codelineno-22-26"></a>
<a id="__codelineno-22-27" name="__codelineno-22-27" href="#__codelineno-22-27"></a>Step 4: Compressed representation
<a id="__codelineno-22-28" name="__codelineno-22-28" href="#__codelineno-22-28"></a>Original: 768 dimensions × 32 bits/float = 24,576 bits per vector (3,072 bytes)
<a id="__codelineno-22-29" name="__codelineno-22-29" href="#__codelineno-22-29"></a>Compressed: 8 chunks × 8 bits/chunk = 64 bits per vector (8 bytes)
<a id="__codelineno-22-30" name="__codelineno-22-30" href="#__codelineno-22-30"></a>Compression ratio: 24,576 ÷ 64 = 384× smaller!
</code></pre></div>
<strong>Mathematical Foundation:</strong></p>
<ul>
<li><strong>Compression ratio</strong>: d/(m·log₂(k)) where d=dimensions, m=subvectors, k=centroids per subvector</li>
<li><strong>Typical setup</strong>: 768D → 8 subvectors of 96D each, 256 centroids per subvector</li>
<li><strong>Memory per vector</strong>: m·log₂(k) = 8·log₂(256) = 8·8 = 64 bits = 8 bytes</li>
</ul>
<p><strong>Memory savings calculation:</strong></p>
<ul>
<li><strong>Original</strong>: 1M vectors × (768 × 4 bytes) = 3.072 GB  </li>
<li><strong>Compressed</strong>: 1M vectors × 8 bytes = 8 MB</li>
<li><strong>Compression</strong>: 384× smaller memory usage!</li>
</ul>
<p><strong>Performance Trade-offs:</strong>
✓ Massive memory reduction (100-400×)
✓ Faster similarity computation (lookup tables)
✓ Better cache performance (more vectors fit in memory)
✗ Small accuracy loss (~2-5% recall drop)
✗ Requires training phase to learn centroids</p>
<p><strong>Hands-on Implementation:</strong></p>
<blockquote>
<p>📓 <strong>Interactive Tutorial:</strong> Explore Product Quantization compression with executable Python code in <a href="../pynb/vector_search/vector_search.ipynb">pynb/vector_search/vector_search.ipynb</a></p>
<p>The notebook demonstrates:
- Vector splitting into subvectors and centroid learning
- Compression ratio calculations (384× memory reduction)
- Asymmetric distance computation for search
- Combined IVF+PQ implementation for best of both worlds</p>
</blockquote>
<p><strong>Performance Comparison with Real Numbers:</strong></p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Search Time (1M docs)</th>
<th>Memory Usage</th>
<th>Recall@10</th>
<th>When to Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Brute Force</strong></td>
<td>77 seconds</td>
<td>3.0 GB</td>
<td>100%</td>
<td>Small datasets (&lt;10K vectors), exact results required</td>
</tr>
<tr>
<td><strong>HNSW</strong></td>
<td>0.02 seconds</td>
<td>4.5 GB</td>
<td>95-99%</td>
<td>Real-time applications, high-dimensional data</td>
</tr>
<tr>
<td><strong>IVF (1000 clusters)</strong></td>
<td>0.08 seconds</td>
<td>3.2 GB</td>
<td>90-95%</td>
<td>Medium datasets, balanced performance needs</td>
</tr>
<tr>
<td><strong>IVF + PQ</strong></td>
<td>0.05 seconds</td>
<td>8 MB</td>
<td>85-92%</td>
<td>Large-scale deployment, memory constraints</td>
</tr>
</tbody>
</table>
<h4 id="from-theory-to-practice-implementing-vector-search">From Theory to Practice: Implementing Vector Search<a class="headerlink" href="#from-theory-to-practice-implementing-vector-search" title="Permanent link">&para;</a></h4>
<p>Now that we understand the mathematical foundations and trade-offs of different indexing methods, let's see how these concepts translate into real-world implementations. While there are many vector database solutions available (Pinecone, Weaviate, Chroma, etc.), we'll use <strong>OpenSearch</strong> as our practical example because:</p>
<ol>
<li><strong>Open source and widely adopted</strong>: Used by many companies for production search</li>
<li><strong>Multiple algorithm support</strong>: Implements HNSW, IVF, and product quantization we just learned about</li>
<li><strong>Mature ecosystem</strong>: Battle-tested with extensive documentation and community support</li>
<li><strong>Hybrid capabilities</strong>: Combines vector search with traditional text search seamlessly</li>
</ol>
<p><strong>What is OpenSearch?</strong>
OpenSearch is an open-source search and analytics engine that started as a fork of Elasticsearch. It has built-in support for k-nearest neighbor (k-NN) search, making it an excellent platform for vector similarity search. Think of it as a database specifically designed for finding similar items quickly.</p>
<p><strong>Why Vector Search in OpenSearch Matters:</strong></p>
<ul>
<li><strong>Real-world scale</strong>: Handles millions of documents in production environments</li>
<li><strong>Production features</strong>: Includes monitoring, scaling, and reliability features you need</li>
<li><strong>Learning bridge</strong>: Understanding OpenSearch patterns helps with other vector databases</li>
</ul>
<p><strong>Mathematical Summary:</strong></p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Time Complexity</th>
<th>Space Complexity</th>
<th>Key Parameters</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Brute Force</strong></td>
<td>O(n·d)</td>
<td>O(n·d)</td>
<td>None</td>
</tr>
<tr>
<td><strong>HNSW</strong></td>
<td>O(log n)</td>
<td>O(n·M)</td>
<td>M=connections, ef=search width</td>
</tr>
<tr>
<td><strong>IVF</strong></td>
<td>O(n/k + k)</td>
<td>O(n·d + k·d)</td>
<td>k=clusters, probes=search clusters</td>
</tr>
<tr>
<td><strong>Product Quantization</strong></td>
<td>O(n·d/m)</td>
<td>O(n·m + k^m)</td>
<td>m=subvectors, k=centroids</td>
</tr>
</tbody>
</table>
<h4 id="comprehensive-hands-on-tutorial">Comprehensive Hands-on Tutorial<a class="headerlink" href="#comprehensive-hands-on-tutorial" title="Permanent link">&para;</a></h4>
<blockquote>
<p>📓 <strong>Complete Implementation Guide:</strong> <a href="../pynb/vector_search/vector_search.ipynb">pynb/vector_search/vector_search.ipynb</a></p>
<p><strong>What you'll build and compare:</strong></p>
<ol>
<li><strong>Brute Force Search</strong> - Baseline implementation with O(n·d) complexity</li>
<li><strong>HNSW Implementation</strong> - Graph-based fast search with parameter tuning</li>
<li><strong>IVF Clustering</strong> - K-means based partitioning with probe optimization  </li>
<li><strong>Product Quantization</strong> - Memory compression with 100-400× reduction</li>
<li><strong>Combined Methods</strong> - IVF+PQ for optimal speed and memory efficiency</li>
</ol>
<p><strong>Interactive Features:</strong>
- <strong>Real benchmarks</strong> with timing comparisons and speedup calculations
- <strong>Performance visualization</strong> showing speed vs accuracy trade-offs
- <strong>Parameter exploration</strong> to understand tuning effects
- <strong>Memory analysis</strong> with compression ratio calculations
- <strong>Production considerations</strong> for choosing the right method</p>
<p><strong>Educational Value:</strong>
- Execute all code step-by-step to understand how each algorithm works
- Modify parameters to see their impact on performance and accuracy
- Compare methods side-by-side with real datasets
- Learn when to use each approach in production systems</p>
</blockquote>
<h4 id="understanding-index-performance-trade-offs">Understanding Index Performance Trade-offs<a class="headerlink" href="#understanding-index-performance-trade-offs" title="Permanent link">&para;</a></h4>
<p>Different indexes optimize for different priorities:</p>
<h4 id="vector-database-terminology-and-index-implementations">Vector Database Terminology and Index Implementations<a class="headerlink" href="#vector-database-terminology-and-index-implementations" title="Permanent link">&para;</a></h4>
<p><strong>Index Performance Characteristics:</strong></p>
<table>
<thead>
<tr>
<th>Index Type</th>
<th>Build Time</th>
<th>Query Time</th>
<th>Memory Usage</th>
<th>Recall</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>IVF_FLAT</strong></td>
<td>O(n)</td>
<td>O(√n)</td>
<td>High (exact vectors)</td>
<td>High</td>
</tr>
<tr>
<td><strong>IVF_PQ</strong></td>
<td>O(n)</td>
<td>O(√n)</td>
<td>Low (compressed)</td>
<td>Medium</td>
</tr>
<tr>
<td><strong>HNSW</strong></td>
<td>O(n log n)</td>
<td>O(log n)</td>
<td>Medium (graph structure)</td>
<td>High</td>
</tr>
<tr>
<td><strong>IVF_SQ8</strong></td>
<td>O(n)</td>
<td>O(√n)</td>
<td>Medium (8-bit quantized)</td>
<td>Medium-High</td>
</tr>
</tbody>
</table>
<p><strong>Practical Example with Our Vocabulary:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a>Document Collection:
<a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a>doc1: &quot;The cat sleeps in house&quot; → vector_1: [0.82, 0.31, 0.15, ...]
<a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a>doc2: &quot;Big dog runs in park&quot; → vector_2: [0.79, 0.25, 0.18, ...]
<a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a>doc3: &quot;Small pet loves plays&quot; → vector_3: [0.75, 0.35, 0.22, ...]
<a id="__codelineno-23-5" name="__codelineno-23-5" href="#__codelineno-23-5"></a>
<a id="__codelineno-23-6" name="__codelineno-23-6" href="#__codelineno-23-6"></a>IVF_FLAT Index:
<a id="__codelineno-23-7" name="__codelineno-23-7" href="#__codelineno-23-7"></a>
<a id="__codelineno-23-8" name="__codelineno-23-8" href="#__codelineno-23-8"></a>- Exact distance computation, high memory usage
<a id="__codelineno-23-9" name="__codelineno-23-9" href="#__codelineno-23-9"></a>- Best for: High-accuracy requirements, smaller datasets
<a id="__codelineno-23-10" name="__codelineno-23-10" href="#__codelineno-23-10"></a>
<a id="__codelineno-23-11" name="__codelineno-23-11" href="#__codelineno-23-11"></a>IVF_PQ Index:
<a id="__codelineno-23-12" name="__codelineno-23-12" href="#__codelineno-23-12"></a>
<a id="__codelineno-23-13" name="__codelineno-23-13" href="#__codelineno-23-13"></a>- Compressed vectors, ~100x memory reduction
<a id="__codelineno-23-14" name="__codelineno-23-14" href="#__codelineno-23-14"></a>- Best for: Large-scale deployment, acceptable recall trade-off
<a id="__codelineno-23-15" name="__codelineno-23-15" href="#__codelineno-23-15"></a>
<a id="__codelineno-23-16" name="__codelineno-23-16" href="#__codelineno-23-16"></a>HNSW Index:
<a id="__codelineno-23-17" name="__codelineno-23-17" href="#__codelineno-23-17"></a>
<a id="__codelineno-23-18" name="__codelineno-23-18" href="#__codelineno-23-18"></a>- Graph navigation, logarithmic search complexity
<a id="__codelineno-23-19" name="__codelineno-23-19" href="#__codelineno-23-19"></a>- Best for: Real-time applications, balanced accuracy/speed
</code></pre></div></p>
<h4 id="vector-database-operations-and-production-considerations">Vector Database Operations and Production Considerations<a class="headerlink" href="#vector-database-operations-and-production-considerations" title="Permanent link">&para;</a></h4>
<p><strong>Insertion Pipeline:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a>1. Document Processing:
<a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a>   &quot;Cats are small animals&quot; → Text preprocessing
<a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a>
<a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a>2. Embedding Generation:
<a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a>   Sentence transformer → [0.84, 0.29, 0.17, ..., 0.43] (768-dim)
<a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a>
<a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a>3. Index Insertion:
<a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a>   HNSW: Add node, connect to M nearest neighbors
<a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a>   IVF: Assign to nearest cluster, append to inverted list
<a id="__codelineno-24-10" name="__codelineno-24-10" href="#__codelineno-24-10"></a>
<a id="__codelineno-24-11" name="__codelineno-24-11" href="#__codelineno-24-11"></a>4. Metadata Association:
<a id="__codelineno-24-12" name="__codelineno-24-12" href="#__codelineno-24-12"></a>   vector_id → {text: &quot;Cats are small animals&quot;, category: &quot;animals&quot;, timestamp: &quot;2024-01-15&quot;}
</code></pre></div></p>
<p><strong>How Search Actually Works:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a>You ask: &quot;What do pets do?&quot;
<a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a>
<a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a>Step 1: Your question becomes numbers: [0.72, 0.31, 0.18, ...]
<a id="__codelineno-25-4" name="__codelineno-25-4" href="#__codelineno-25-4"></a>Step 2: Compare against all stored documents
<a id="__codelineno-25-5" name="__codelineno-25-5" href="#__codelineno-25-5"></a>Step 3: Only keep results labeled &quot;animals&quot; (if you want)
<a id="__codelineno-25-6" name="__codelineno-25-6" href="#__codelineno-25-6"></a>Step 4: Sort by how similar they are:
<a id="__codelineno-25-7" name="__codelineno-25-7" href="#__codelineno-25-7"></a>
<a id="__codelineno-25-8" name="__codelineno-25-8" href="#__codelineno-25-8"></a>   - doc3: &quot;Dogs like to play fetch&quot; (91% similar) ✓
<a id="__codelineno-25-9" name="__codelineno-25-9" href="#__codelineno-25-9"></a>   - doc1: &quot;Cats enjoy sleeping&quot; (87% similar) ✓
<a id="__codelineno-25-10" name="__codelineno-25-10" href="#__codelineno-25-10"></a>   - doc5: &quot;Houses need cleaning&quot; (85% similar, but about places) ✗
</code></pre></div></p>
<p><strong>Handling Large Databases:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a>When you have millions of documents, you split them across multiple servers:
<a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a>
<a id="__codelineno-26-3" name="__codelineno-26-3" href="#__codelineno-26-3"></a>Server 1: documents 1 to 1 million
<a id="__codelineno-26-4" name="__codelineno-26-4" href="#__codelineno-26-4"></a>Server 2: documents 1 million to 2 million  
<a id="__codelineno-26-5" name="__codelineno-26-5" href="#__codelineno-26-5"></a>Server 3: documents 2 million to 3 million
<a id="__codelineno-26-6" name="__codelineno-26-6" href="#__codelineno-26-6"></a>
<a id="__codelineno-26-7" name="__codelineno-26-7" href="#__codelineno-26-7"></a>When you search:
<a id="__codelineno-26-8" name="__codelineno-26-8" href="#__codelineno-26-8"></a>
<a id="__codelineno-26-9" name="__codelineno-26-9" href="#__codelineno-26-9"></a>1. Ask all servers at the same time
<a id="__codelineno-26-10" name="__codelineno-26-10" href="#__codelineno-26-10"></a>2. Each server gives you its best results
<a id="__codelineno-26-11" name="__codelineno-26-11" href="#__codelineno-26-11"></a>3. Combine all results and pick the overall best ones
<a id="__codelineno-26-12" name="__codelineno-26-12" href="#__codelineno-26-12"></a>4. Send final results back to you
<a id="__codelineno-26-13" name="__codelineno-26-13" href="#__codelineno-26-13"></a>
<a id="__codelineno-26-14" name="__codelineno-26-14" href="#__codelineno-26-14"></a>This makes searches faster even with huge databases.
</code></pre></div></p>
<p><strong>Adding New Documents:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a>When you add new documents to your database:
<a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a>
<a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a>For HNSW (building-style): Add the new document as a &quot;room&quot; and connect it to nearby &quot;rooms&quot;
<a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a>For IVF (filing cabinet-style): Figure out which &quot;cabinet&quot; it belongs in and file it there
<a id="__codelineno-27-5" name="__codelineno-27-5" href="#__codelineno-27-5"></a>
<a id="__codelineno-27-6" name="__codelineno-27-6" href="#__codelineno-27-6"></a>Keeping the database healthy:
<a id="__codelineno-27-7" name="__codelineno-27-7" href="#__codelineno-27-7"></a>
<a id="__codelineno-27-8" name="__codelineno-27-8" href="#__codelineno-27-8"></a>- Occasionally reorganize everything for better performance
<a id="__codelineno-27-9" name="__codelineno-27-9" href="#__codelineno-27-9"></a>- Clean up deleted documents in the background  
<a id="__codelineno-27-10" name="__codelineno-27-10" href="#__codelineno-27-10"></a>- Rebalance when you add lots of new content
<a id="__codelineno-27-11" name="__codelineno-27-11" href="#__codelineno-27-11"></a>
<a id="__codelineno-27-12" name="__codelineno-27-12" href="#__codelineno-27-12"></a>When you upgrade your embedding model (the thing that turns text into numbers):
<a id="__codelineno-27-13" name="__codelineno-27-13" href="#__codelineno-27-13"></a>
<a id="__codelineno-27-14" name="__codelineno-27-14" href="#__codelineno-27-14"></a>- Keep both old and new versions running at the same time
<a id="__codelineno-27-15" name="__codelineno-27-15" href="#__codelineno-27-15"></a>- Gradually move documents from old format to new format
</code></pre></div></p>
<hr />
<h2 id="part-ii-generation-and-retrieval-control">PART II: Generation and Retrieval Control<a class="headerlink" href="#part-ii-generation-and-retrieval-control" title="Permanent link">&para;</a></h2>
<h3 id="3-controlling-randomness-temperature-top-k-and-top-p-in-llms-and-vector-stores">3. Controlling Randomness: Temperature, Top-K, and Top-P in LLMs and Vector Stores<a class="headerlink" href="#3-controlling-randomness-temperature-top-k-and-top-p-in-llms-and-vector-stores" title="Permanent link">&para;</a></h3>
<p><strong>Why Control Randomness?</strong></p>
<p>Both LLMs and vector stores deal with probability distributions and ranking. Understanding how to control randomness and selection helps optimize both systems for different use cases.</p>
<h4 id="temperature-top-k-top-p-in-llm-text-generation">Temperature, Top-K, Top-P in LLM Text Generation<a class="headerlink" href="#temperature-top-k-top-p-in-llm-text-generation" title="Permanent link">&para;</a></h4>
<p><strong>The Problem: Deterministic vs Creative Output</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a>LLM Next-Token Prediction for &quot;The cat is ___&quot;:
<a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a>Raw probabilities: [animal: 0.4, big: 0.25, sleeping: 0.15, running: 0.1, purple: 0.05, ...]
<a id="__codelineno-28-3" name="__codelineno-28-3" href="#__codelineno-28-3"></a>
<a id="__codelineno-28-4" name="__codelineno-28-4" href="#__codelineno-28-4"></a>Without controls:
<a id="__codelineno-28-5" name="__codelineno-28-5" href="#__codelineno-28-5"></a>
<a id="__codelineno-28-6" name="__codelineno-28-6" href="#__codelineno-28-6"></a>- Always pick highest probability → &quot;The cat is animal&quot; (repetitive)
<a id="__codelineno-28-7" name="__codelineno-28-7" href="#__codelineno-28-7"></a>- Pick randomly → &quot;The cat is purple&quot; (nonsensical)
<a id="__codelineno-28-8" name="__codelineno-28-8" href="#__codelineno-28-8"></a>
<a id="__codelineno-28-9" name="__codelineno-28-9" href="#__codelineno-28-9"></a>We need balanced control between coherence and creativity
</code></pre></div>
<p><strong>Temperature: Controlling Confidence</strong></p>
<p>Temperature adjusts the "sharpness" of probability distributions:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a>Original probabilities: [animal: 0.4, big: 0.25, sleeping: 0.15, running: 0.1, purple: 0.05]
<a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a>
<a id="__codelineno-29-3" name="__codelineno-29-3" href="#__codelineno-29-3"></a>Temperature = 0.1 (Low temperature, high confidence):
<a id="__codelineno-29-4" name="__codelineno-29-4" href="#__codelineno-29-4"></a>Softmax with T=0.1: [animal: 0.85, big: 0.12, sleeping: 0.02, running: 0.01, purple: 0.00]
<a id="__codelineno-29-5" name="__codelineno-29-5" href="#__codelineno-29-5"></a>Effect: Very predictable, focused on highest probability
<a id="__codelineno-29-6" name="__codelineno-29-6" href="#__codelineno-29-6"></a>
<a id="__codelineno-29-7" name="__codelineno-29-7" href="#__codelineno-29-7"></a>Temperature = 1.0 (Neutral):  
<a id="__codelineno-29-8" name="__codelineno-29-8" href="#__codelineno-29-8"></a>Unchanged: [animal: 0.4, big: 0.25, sleeping: 0.15, running: 0.1, purple: 0.05]
<a id="__codelineno-29-9" name="__codelineno-29-9" href="#__codelineno-29-9"></a>Effect: Balanced selection
<a id="__codelineno-29-10" name="__codelineno-29-10" href="#__codelineno-29-10"></a>
<a id="__codelineno-29-11" name="__codelineno-29-11" href="#__codelineno-29-11"></a>Temperature = 2.0 (High temperature, low confidence):
<a id="__codelineno-29-12" name="__codelineno-29-12" href="#__codelineno-29-12"></a>Softmax with T=2.0: [animal: 0.28, big: 0.23, sleeping: 0.19, running: 0.16, purple: 0.14]
<a id="__codelineno-29-13" name="__codelineno-29-13" href="#__codelineno-29-13"></a>Effect: More random, creative but potentially incoherent
<a id="__codelineno-29-14" name="__codelineno-29-14" href="#__codelineno-29-14"></a>
<a id="__codelineno-29-15" name="__codelineno-29-15" href="#__codelineno-29-15"></a>Formula: softmax(logits/temperature)
</code></pre></div>
<p><strong>Top-K: Limiting Vocabulary</strong></p>
<p>Top-K keeps only the K most likely tokens:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a>Original: [animal: 0.4, big: 0.25, sleeping: 0.15, running: 0.1, purple: 0.05, flying: 0.03, ...]
<a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a>
<a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a>Top-K = 3:
<a id="__codelineno-30-4" name="__codelineno-30-4" href="#__codelineno-30-4"></a>Filtered: [animal: 0.4, big: 0.25, sleeping: 0.15]
<a id="__codelineno-30-5" name="__codelineno-30-5" href="#__codelineno-30-5"></a>Renormalized: [animal: 0.5, big: 0.31, sleeping: 0.19]
<a id="__codelineno-30-6" name="__codelineno-30-6" href="#__codelineno-30-6"></a>Effect: Removes unlikely options, prevents weird completions
<a id="__codelineno-30-7" name="__codelineno-30-7" href="#__codelineno-30-7"></a>
<a id="__codelineno-30-8" name="__codelineno-30-8" href="#__codelineno-30-8"></a>Top-K = 1:  
<a id="__codelineno-30-9" name="__codelineno-30-9" href="#__codelineno-30-9"></a>Result: [animal: 1.0]
<a id="__codelineno-30-10" name="__codelineno-30-10" href="#__codelineno-30-10"></a>Effect: Deterministic, always picks most likely token
</code></pre></div>
<p><strong>Top-P (Nucleus Sampling): Dynamic Vocabulary</strong></p>
<p>Top-P keeps tokens until cumulative probability reaches P:</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a>Sorted probabilities: [animal: 0.4, big: 0.25, sleeping: 0.15, running: 0.1, purple: 0.05, ...]
<a id="__codelineno-31-2" name="__codelineno-31-2" href="#__codelineno-31-2"></a>
<a id="__codelineno-31-3" name="__codelineno-31-3" href="#__codelineno-31-3"></a>Top-P = 0.8:
<a id="__codelineno-31-4" name="__codelineno-31-4" href="#__codelineno-31-4"></a>Cumulative: animal(0.4) + big(0.25) + sleeping(0.15) = 0.8 ← stop here
<a id="__codelineno-31-5" name="__codelineno-31-5" href="#__codelineno-31-5"></a>Kept: [animal: 0.4, big: 0.25, sleeping: 0.15]  
<a id="__codelineno-31-6" name="__codelineno-31-6" href="#__codelineno-31-6"></a>Renormalized: [animal: 0.5, big: 0.31, sleeping: 0.19]
<a id="__codelineno-31-7" name="__codelineno-31-7" href="#__codelineno-31-7"></a>
<a id="__codelineno-31-8" name="__codelineno-31-8" href="#__codelineno-31-8"></a>Top-P = 0.9:
<a id="__codelineno-31-9" name="__codelineno-31-9" href="#__codelineno-31-9"></a>Cumulative: animal(0.4) + big(0.25) + sleeping(0.15) + running(0.1) = 0.9
<a id="__codelineno-31-10" name="__codelineno-31-10" href="#__codelineno-31-10"></a>Kept: [animal: 0.4, big: 0.25, sleeping: 0.15, running: 0.1]
<a id="__codelineno-31-11" name="__codelineno-31-11" href="#__codelineno-31-11"></a>Effect: Adaptive vocabulary size based on probability distribution
</code></pre></div>
<p><strong>Practical LLM Generation Settings:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a>Creative Writing: Temperature=1.2, Top-P=0.9
<a id="__codelineno-32-2" name="__codelineno-32-2" href="#__codelineno-32-2"></a>
<a id="__codelineno-32-3" name="__codelineno-32-3" href="#__codelineno-32-3"></a>- More diverse, interesting outputs
<a id="__codelineno-32-4" name="__codelineno-32-4" href="#__codelineno-32-4"></a>- Higher chance of creative but coherent text
<a id="__codelineno-32-5" name="__codelineno-32-5" href="#__codelineno-32-5"></a>
<a id="__codelineno-32-6" name="__codelineno-32-6" href="#__codelineno-32-6"></a>Code Generation: Temperature=0.2, Top-K=10  
<a id="__codelineno-32-7" name="__codelineno-32-7" href="#__codelineno-32-7"></a>
<a id="__codelineno-32-8" name="__codelineno-32-8" href="#__codelineno-32-8"></a>- Focused on most likely completions
<a id="__codelineno-32-9" name="__codelineno-32-9" href="#__codelineno-32-9"></a>- Reduces syntax errors and nonsensical code
<a id="__codelineno-32-10" name="__codelineno-32-10" href="#__codelineno-32-10"></a>
<a id="__codelineno-32-11" name="__codelineno-32-11" href="#__codelineno-32-11"></a>Factual Q&amp;A: Temperature=0.1, Top-K=5
<a id="__codelineno-32-12" name="__codelineno-32-12" href="#__codelineno-32-12"></a>
<a id="__codelineno-32-13" name="__codelineno-32-13" href="#__codelineno-32-13"></a>- Highly deterministic answers
<a id="__codelineno-32-14" name="__codelineno-32-14" href="#__codelineno-32-14"></a>- Minimizes hallucination risk
</code></pre></div>
<h4 id="how-vector-stores-handle-search-control">How Vector Stores Handle Search Control<a class="headerlink" href="#how-vector-stores-handle-search-control" title="Permanent link">&para;</a></h4>
<p>Just like LLMs use temperature and sampling to control text generation, vector stores have their own ways to control search results. The concepts are surprisingly similar!</p>
<p><strong>Similarity Threshold (Like Temperature Control)</strong></p>
<p>When you search a vector database, you get back documents with similarity scores. Just like temperature controls how "picky" an LLM is about word choices, similarity thresholds control how "picky" your search is about results.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a>Simple Example: Searching for &quot;What animals make good pets?&quot;
<a id="__codelineno-33-2" name="__codelineno-33-2" href="#__codelineno-33-2"></a>Similarity scores: [doc1: 0.95, doc2: 0.78, doc3: 0.65, doc4: 0.45, doc5: 0.23]
<a id="__codelineno-33-3" name="__codelineno-33-3" href="#__codelineno-33-3"></a>
<a id="__codelineno-33-4" name="__codelineno-33-4" href="#__codelineno-33-4"></a>High threshold (0.8): Like low temperature in LLMs
<a id="__codelineno-33-5" name="__codelineno-33-5" href="#__codelineno-33-5"></a>Only return: [doc1: 0.95] 
<a id="__codelineno-33-6" name="__codelineno-33-6" href="#__codelineno-33-6"></a>Result: Very picky, only the best match
<a id="__codelineno-33-7" name="__codelineno-33-7" href="#__codelineno-33-7"></a>Good for: When you need exact information (like medical advice)
<a id="__codelineno-33-8" name="__codelineno-33-8" href="#__codelineno-33-8"></a>
<a id="__codelineno-33-9" name="__codelineno-33-9" href="#__codelineno-33-9"></a>Medium threshold (0.6): Like moderate temperature
<a id="__codelineno-33-10" name="__codelineno-33-10" href="#__codelineno-33-10"></a>Return: [doc1: 0.95, doc2: 0.78, doc3: 0.65]  
<a id="__codelineno-33-11" name="__codelineno-33-11" href="#__codelineno-33-11"></a>Result: Balanced - good quality but some variety
<a id="__codelineno-33-12" name="__codelineno-33-12" href="#__codelineno-33-12"></a>Good for: General search, typical Q&amp;A systems
<a id="__codelineno-33-13" name="__codelineno-33-13" href="#__codelineno-33-13"></a>
<a id="__codelineno-33-14" name="__codelineno-33-14" href="#__codelineno-33-14"></a>Low threshold (0.4): Like high temperature
<a id="__codelineno-33-15" name="__codelineno-33-15" href="#__codelineno-33-15"></a>Return: [doc1: 0.95, doc2: 0.78, doc3: 0.65, doc4: 0.45]
<a id="__codelineno-33-16" name="__codelineno-33-16" href="#__codelineno-33-16"></a>Result: Less picky, more diverse results
<a id="__codelineno-33-17" name="__codelineno-33-17" href="#__codelineno-33-17"></a>Good for: Exploring ideas, brainstorming, research
</code></pre></div>
<p><strong>Top-K Results (Identical Concept)</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a>Vector search Top-K = 3:
<a id="__codelineno-34-2" name="__codelineno-34-2" href="#__codelineno-34-2"></a>Return top 3 most similar documents regardless of similarity scores
<a id="__codelineno-34-3" name="__codelineno-34-3" href="#__codelineno-34-3"></a>Useful for: Fixed-size result sets, pagination
<a id="__codelineno-34-4" name="__codelineno-34-4" href="#__codelineno-34-4"></a>
<a id="__codelineno-34-5" name="__codelineno-34-5" href="#__codelineno-34-5"></a>Vector search Top-K = 1:
<a id="__codelineno-34-6" name="__codelineno-34-6" href="#__codelineno-34-6"></a>Return only the most similar document  
<a id="__codelineno-34-7" name="__codelineno-34-7" href="#__codelineno-34-7"></a>Useful for: Finding single best match
</code></pre></div>
<p><strong>Similarity Cutoff (Like Top-P)</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a>Dynamic result size based on similarity quality:
<a id="__codelineno-35-2" name="__codelineno-35-2" href="#__codelineno-35-2"></a>
<a id="__codelineno-35-3" name="__codelineno-35-3" href="#__codelineno-35-3"></a>Cumulative similarity approach:
<a id="__codelineno-35-4" name="__codelineno-35-4" href="#__codelineno-35-4"></a>
<a id="__codelineno-35-5" name="__codelineno-35-5" href="#__codelineno-35-5"></a>- Sort by similarity: [0.95, 0.78, 0.65, 0.45, 0.23]
<a id="__codelineno-35-6" name="__codelineno-35-6" href="#__codelineno-35-6"></a>- Return documents until similarity drops below threshold
<a id="__codelineno-35-7" name="__codelineno-35-7" href="#__codelineno-35-7"></a>- Adaptive result set size based on query quality
<a id="__codelineno-35-8" name="__codelineno-35-8" href="#__codelineno-35-8"></a>
<a id="__codelineno-35-9" name="__codelineno-35-9" href="#__codelineno-35-9"></a>Similarity gap approach:
<a id="__codelineno-35-10" name="__codelineno-35-10" href="#__codelineno-35-10"></a>
<a id="__codelineno-35-11" name="__codelineno-35-11" href="#__codelineno-35-11"></a>- Stop when gap between consecutive results exceeds threshold
<a id="__codelineno-35-12" name="__codelineno-35-12" href="#__codelineno-35-12"></a>- doc1: 0.95, doc2: 0.78 (gap: 0.17)
<a id="__codelineno-35-13" name="__codelineno-35-13" href="#__codelineno-35-13"></a>- If gap_threshold = 0.15, stop after doc1
</code></pre></div>
<p><strong>Practical Vector Store Settings:</strong></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a>High-Precision Search: High threshold (0.8), Top-K=5
<a id="__codelineno-36-2" name="__codelineno-36-2" href="#__codelineno-36-2"></a>
<a id="__codelineno-36-3" name="__codelineno-36-3" href="#__codelineno-36-3"></a>- Medical/legal documents
<a id="__codelineno-36-4" name="__codelineno-36-4" href="#__codelineno-36-4"></a>- Exact information retrieval
<a id="__codelineno-36-5" name="__codelineno-36-5" href="#__codelineno-36-5"></a>
<a id="__codelineno-36-6" name="__codelineno-36-6" href="#__codelineno-36-6"></a>Exploratory Search: Low threshold (0.5), Top-K=20
<a id="__codelineno-36-7" name="__codelineno-36-7" href="#__codelineno-36-7"></a>
<a id="__codelineno-36-8" name="__codelineno-36-8" href="#__codelineno-36-8"></a>- Research, brainstorming  
<a id="__codelineno-36-9" name="__codelineno-36-9" href="#__codelineno-36-9"></a>- Cast wider net for ideas
<a id="__codelineno-36-10" name="__codelineno-36-10" href="#__codelineno-36-10"></a>
<a id="__codelineno-36-11" name="__codelineno-36-11" href="#__codelineno-36-11"></a>Real-time Chat: Medium threshold (0.7), Top-K=10
<a id="__codelineno-36-12" name="__codelineno-36-12" href="#__codelineno-36-12"></a>
<a id="__codelineno-36-13" name="__codelineno-36-13" href="#__codelineno-36-13"></a>- Balance relevance and response speed
<a id="__codelineno-36-14" name="__codelineno-36-14" href="#__codelineno-36-14"></a>- Sufficient context without overwhelming LLM
</code></pre></div>
<hr />
<h2 id="part-iii-mathematical-foundations">PART III: Mathematical Foundations<a class="headerlink" href="#part-iii-mathematical-foundations" title="Permanent link">&para;</a></h2>
<h3 id="comprehensive-mathematical-resources">Comprehensive Mathematical Resources<a class="headerlink" href="#comprehensive-mathematical-resources" title="Permanent link">&para;</a></h3>
<p>This document focuses on conceptual understanding. For detailed mathematical derivations, formal proofs, and implementation details, please consult our dedicated mathematical resources:</p>
<h4 id="transformers-mathematics-guide-part-1"><a href="../transformers_math1/">Transformers Mathematics Guide Part 1</a><a class="headerlink" href="#transformers-mathematics-guide-part-1" title="Permanent link">&para;</a></h4>
<p><strong>Essential sections for this document:</strong>
- <strong>Sections 2.1-2.3:</strong> Mathematical preliminaries (linear algebra, matrix calculus, probability theory)
- <strong>Section 4.2-4.3:</strong> High-dimensional geometry and similarity metrics (cosine similarity, euclidean distance, concentration of measure)
- <strong>Section 5:</strong> Attention mechanism derivations (scaled dot-product attention, softmax gradients, backpropagation)<br />
- <strong>Section 6:</strong> Multi-head attention mathematics (subspace projections, positional encodings, RoPE)</p>
<h4 id="transformers-mathematics-guide-part-2"><a href="../transformers_math2/">Transformers Mathematics Guide Part 2</a><a class="headerlink" href="#transformers-mathematics-guide-part-2" title="Permanent link">&para;</a></h4>
<p><strong>Essential sections for this document:</strong>
- <strong>Section 9:</strong> Optimization theory (gradient descent, Adam optimizer, learning rate schedules)
- <strong>Section 10:</strong> Efficient attention implementations for scaling
- <strong>Section 11:</strong> Regularization and calibration techniques</p>
<h4 id="mathematical-quick-reference"><a href="../math_quick_ref/">Mathematical Quick Reference</a><a class="headerlink" href="#mathematical-quick-reference" title="Permanent link">&para;</a></h4>
<p><strong>Quick lookup for:</strong></p>
<ul>
<li>Linear algebra operations (matrix multiplication, transpose, eigenvalues)</li>
<li>Vector geometry (dot products, norms, similarity metrics)</li>
<li>Calculus fundamentals (derivatives, gradients, chain rule)</li>
<li>Probability &amp; statistics (expectation, variance, softmax, cross-entropy)</li>
<li>Optimization algorithms (gradient descent, Adam, learning rate scheduling)</li>
<li>Transformer components (attention mechanisms, layer normalization, residual connections)</li>
</ul>
<h3 id="mathematical-foundations-summary">Mathematical Foundations Summary<a class="headerlink" href="#mathematical-foundations-summary" title="Permanent link">&para;</a></h3>
<p>The mathematical concepts underlying both LLM weights and vector stores share common foundations in high-dimensional linear algebra and optimization theory. Key mathematical principles include:</p>
<hr />
<h2 id="part-iv-system-comparison-and-integration">PART IV: System Comparison and Integration<a class="headerlink" href="#part-iv-system-comparison-and-integration" title="Permanent link">&para;</a></h2>
<h3 id="4-critical-question-are-they-the-same-concept">4. Critical Question: Are They the Same Concept?<a class="headerlink" href="#4-critical-question-are-they-the-same-concept" title="Permanent link">&para;</a></h3>
<p><strong>NO</strong> - These are fundamentally different approaches:</p>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>LLM Weights</th>
<th>Vector Stores</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Storage</strong></td>
<td>Distributed patterns</td>
<td>Discrete vectors</td>
</tr>
<tr>
<td><strong>Knowledge Access</strong></td>
<td>Generated through computation</td>
<td>Retrieved through search</td>
</tr>
<tr>
<td><strong>Updates</strong></td>
<td>Requires retraining</td>
<td>Add/remove vectors</td>
</tr>
<tr>
<td><strong>Capacity</strong></td>
<td>Limited by parameter count</td>
<td>Unlimited external storage</td>
</tr>
<tr>
<td><strong>Latency</strong></td>
<td>Fixed computation cost</td>
<td>Variable search cost</td>
</tr>
</tbody>
</table>
<h3 id="5-similarity-calculations-across-systems">5. Similarity Calculations Across Systems<a class="headerlink" href="#5-similarity-calculations-across-systems" title="Permanent link">&para;</a></h3>
<p>Both LLM weights and vector stores fundamentally rely on similarity calculations, but they use them in distinctly different ways:</p>
<h4 id="how-llms-use-similarity">How LLMs Use Similarity<a class="headerlink" href="#how-llms-use-similarity" title="Permanent link">&para;</a></h4>
<p><strong>During Training:</strong></p>
<ul>
<li>
<p><strong>Attention Mechanism:</strong> Uses dot products (related to cosine similarity)
  <div class="highlight"><pre><span></span><code><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a>Attention(Q,K,V) = softmax(QK^T/√d)V
</code></pre></div>
  The QK^T operation computes similarity between query and key vectors.</p>
</li>
<li>
<p><strong>Gradient Flow:</strong> Backpropagation updates weights based on similarity between predicted and actual tokens.</p>
</li>
<li><strong>Example:</strong> When processing "The big cat ___", attention weights learn that "cat" tokens should attend strongly to "animal" tokens.</li>
</ul>
<p><strong>During Inference:</strong></p>
<ul>
<li><strong>No explicit similarity search</strong> - knowledge emerges from distributed computation</li>
<li><strong>Next-token prediction:</strong> Computes probability distributions over vocabulary</li>
<li><strong>Example:</strong> For "The big cat ___", the model outputs P("runs") = 0.3, P("sleeps") = 0.25 through learned weight patterns</li>
</ul>
<h4 id="how-vector-stores-use-similarity">How Vector Stores Use Similarity<a class="headerlink" href="#how-vector-stores-use-similarity" title="Permanent link">&para;</a></h4>
<p><strong>Explicit similarity search for retrieval:</strong></p>
<p><strong>Unified Example - Query: "What animals make good pets?"</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a>Step 1: Query → Embedding
<a id="__codelineno-38-2" name="__codelineno-38-2" href="#__codelineno-38-2"></a>&quot;What animals make good pets?&quot; → [0.72, 0.31, 0.18]
<a id="__codelineno-38-3" name="__codelineno-38-3" href="#__codelineno-38-3"></a>
<a id="__codelineno-38-4" name="__codelineno-38-4" href="#__codelineno-38-4"></a>Step 2: Compare Against All Documents
<a id="__codelineno-38-5" name="__codelineno-38-5" href="#__codelineno-38-5"></a>doc1: &quot;Cats are popular pets&quot; → [0.82, 0.31, 0.15]
<a id="__codelineno-38-6" name="__codelineno-38-6" href="#__codelineno-38-6"></a>doc2: &quot;Dogs make loyal companions&quot; → [0.79, 0.33, 0.18]  
<a id="__codelineno-38-7" name="__codelineno-38-7" href="#__codelineno-38-7"></a>doc3: &quot;Houses need maintenance&quot; → [0.12, 0.85, 0.43]
<a id="__codelineno-38-8" name="__codelineno-38-8" href="#__codelineno-38-8"></a>
<a id="__codelineno-38-9" name="__codelineno-38-9" href="#__codelineno-38-9"></a>Step 3: Calculate Similarities
<a id="__codelineno-38-10" name="__codelineno-38-10" href="#__codelineno-38-10"></a>cosine(query, doc1) = 0.94 ← High relevance
<a id="__codelineno-38-11" name="__codelineno-38-11" href="#__codelineno-38-11"></a>cosine(query, doc2) = 0.96 ← Highest relevance  
<a id="__codelineno-38-12" name="__codelineno-38-12" href="#__codelineno-38-12"></a>cosine(query, doc3) = 0.32 ← Low relevance
<a id="__codelineno-38-13" name="__codelineno-38-13" href="#__codelineno-38-13"></a>
<a id="__codelineno-38-14" name="__codelineno-38-14" href="#__codelineno-38-14"></a>Step 4: Apply Thresholds and Ranking
<a id="__codelineno-38-15" name="__codelineno-38-15" href="#__codelineno-38-15"></a>threshold = 0.5 → docs 1&amp;2 pass, doc3 filtered out
<a id="__codelineno-38-16" name="__codelineno-38-16" href="#__codelineno-38-16"></a>Final ranking: doc2 (0.96), doc1 (0.94)
</code></pre></div></p>
<p><strong>Key Distinction:</strong></p>
<ul>
<li><strong>LLMs</strong>: Internal similarity for attention → generates new content</li>
<li>
<p><strong>Vector Stores</strong>: External similarity for retrieval → finds existing content</p>
</li>
<li>
<p><strong>RAG Pipeline (Retrieval-Augmented Generation):</strong></p>
</li>
</ul>
<p><strong>Complete Workflow:</strong>
<div class="highlight"><pre><span></span><code><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a>Step 1: User Query Processing
<a id="__codelineno-39-2" name="__codelineno-39-2" href="#__codelineno-39-2"></a>User: &quot;What do cats eat in the wild?&quot;
<a id="__codelineno-39-3" name="__codelineno-39-3" href="#__codelineno-39-3"></a>↓
<a id="__codelineno-39-4" name="__codelineno-39-4" href="#__codelineno-39-4"></a>LLM creates query embedding: [0.75, 0.25, 0.15, ...]
<a id="__codelineno-39-5" name="__codelineno-39-5" href="#__codelineno-39-5"></a>
<a id="__codelineno-39-6" name="__codelineno-39-6" href="#__codelineno-39-6"></a>Step 2: Vector Store Retrieval  
<a id="__codelineno-39-7" name="__codelineno-39-7" href="#__codelineno-39-7"></a>Query embedding → Vector database search
<a id="__codelineno-39-8" name="__codelineno-39-8" href="#__codelineno-39-8"></a>↓
<a id="__codelineno-39-9" name="__codelineno-39-9" href="#__codelineno-39-9"></a>Top matching documents:
<a id="__codelineno-39-10" name="__codelineno-39-10" href="#__codelineno-39-10"></a>
<a id="__codelineno-39-11" name="__codelineno-39-11" href="#__codelineno-39-11"></a>- Doc A: &quot;Wild cats hunt small mammals...&quot; (similarity: 0.94)
<a id="__codelineno-39-12" name="__codelineno-39-12" href="#__codelineno-39-12"></a>- Doc B: &quot;Feline dietary patterns in nature...&quot; (similarity: 0.87)
<a id="__codelineno-39-13" name="__codelineno-39-13" href="#__codelineno-39-13"></a>- Doc C: &quot;Natural hunting behaviors of cats...&quot; (similarity: 0.82)
<a id="__codelineno-39-14" name="__codelineno-39-14" href="#__codelineno-39-14"></a>
<a id="__codelineno-39-15" name="__codelineno-39-15" href="#__codelineno-39-15"></a>Step 3: Context Augmentation
<a id="__codelineno-39-16" name="__codelineno-39-16" href="#__codelineno-39-16"></a>Retrieved documents + Original query → Enhanced prompt
<a id="__codelineno-39-17" name="__codelineno-39-17" href="#__codelineno-39-17"></a>&quot;Context: [Doc A, Doc B, Doc C content]
<a id="__codelineno-39-18" name="__codelineno-39-18" href="#__codelineno-39-18"></a>Question: What do cats eat in the wild?
<a id="__codelineno-39-19" name="__codelineno-39-19" href="#__codelineno-39-19"></a>Answer:&quot;
<a id="__codelineno-39-20" name="__codelineno-39-20" href="#__codelineno-39-20"></a>
<a id="__codelineno-39-21" name="__codelineno-39-21" href="#__codelineno-39-21"></a>Step 4: LLM Generation
<a id="__codelineno-39-22" name="__codelineno-39-22" href="#__codelineno-39-22"></a>LLM processes augmented prompt → Generates informed response
<a id="__codelineno-39-23" name="__codelineno-39-23" href="#__codelineno-39-23"></a>&quot;Based on the provided sources, wild cats primarily hunt small mammals...&quot;
</code></pre></div></p>
<p><strong>Key Benefits:</strong></p>
<ul>
<li><strong>Current information</strong>: Vector store provides up-to-date facts</li>
<li><strong>Source attribution</strong>: Clear traceability to retrieved documents  </li>
<li><strong>Reduced hallucination</strong>: LLM responses grounded in real data</li>
</ul>
<h3 id="6-practical-integration">6. Practical Integration<a class="headerlink" href="#6-practical-integration" title="Permanent link">&para;</a></h3>
<h4 id="complementary-systems">Complementary Systems<a class="headerlink" href="#complementary-systems" title="Permanent link">&para;</a></h4>
<p><strong>How LLMs and vector stores work together:</strong></p>
<ol>
<li><strong>LLM Weights Store:</strong> General language patterns, reasoning capabilities, common knowledge</li>
<li><strong>Vector Stores Handle:</strong> Specific facts, recent information, large knowledge bases</li>
</ol>
<p><strong>Trade-offs:</strong></p>
<table>
<thead>
<tr>
<th>Factor</th>
<th>LLM Weights</th>
<th>Vector Stores</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Speed</strong></td>
<td>Fast (fixed computation)</td>
<td>Variable (depends on index size)</td>
</tr>
<tr>
<td><strong>Updates</strong></td>
<td>Slow (retraining required)</td>
<td>Fast (add/remove vectors)</td>
</tr>
<tr>
<td><strong>Accuracy</strong></td>
<td>High for trained knowledge</td>
<td>High for indexed content</td>
</tr>
<tr>
<td><strong>Cost</strong></td>
<td>High inference cost</td>
<td>Storage + search cost</td>
</tr>
</tbody>
</table>
<h4 id="concrete-comparative-example">Concrete Comparative Example<a class="headerlink" href="#concrete-comparative-example" title="Permanent link">&para;</a></h4>
<p><strong>Sentence:</strong> "Small pet loves park"</p>
<p><strong>In LLM Weights:</strong></p>
<ul>
<li>Training updates attention patterns between "small"→"pet", "pet"→"loves", "loves"→"park"</li>
<li>Knowledge encoded as probability: P("loves"|"small pet") = 0.15</li>
<li>Retrieved through forward pass computation</li>
</ul>
<p><strong>In Vector Store:</strong></p>
<ul>
<li>Document: "Small pets love spending time in parks" → Vector: [0.45, 0.67, 0.22]</li>
<li>Query: "pet activities" → Vector: [0.43, 0.65, 0.24]</li>
<li>Cosine similarity: 0.98 → Document retrieved</li>
<li>Knowledge accessed through explicit search</li>
</ul>
<p><strong>Key Difference:</strong> LLM generates the relationship through learned patterns, while vector store retrieves pre-existing representations.</p>
<h4 id="system-limitations-and-considerations">System Limitations and Considerations<a class="headerlink" href="#system-limitations-and-considerations" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>System</th>
<th>Key Limitations</th>
<th>Mitigation Strategies</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>LLM Weights</strong></td>
<td>• Hallucinations and confabulation<br>• Outdated information (training cutoff)<br>• Expensive retraining for updates<br>• Fixed knowledge capacity</td>
<td>• Use confidence scoring<br>• Combine with retrieval systems<br>• Regular model updates<br>• Parameter-efficient fine-tuning</td>
</tr>
<tr>
<td><strong>Vector Stores</strong></td>
<td>• Dependent on embedding quality<br>• Potential stale/outdated data<br>• Limited semantic understanding<br>• Retrieval relevance challenges</td>
<td>• High-quality embedding models<br>• Regular data refreshing<br>• Hybrid search (semantic + keyword)<br>• Query expansion techniques</td>
</tr>
</tbody>
</table>
<hr />
<p><em>For definitions of technical terms used in this document, see the <a href="../glossary/">Glossary</a>.</em></p>
<hr />
<h2 id="conclusion">Conclusion<a class="headerlink" href="#conclusion" title="Permanent link">&para;</a></h2>
<p>This comprehensive exploration reveals that LLM weights and vector stores represent <strong>fundamentally different yet complementary approaches</strong> to knowledge storage and retrieval:</p>
<h3 id="key-distinctions">Key Distinctions<a class="headerlink" href="#key-distinctions" title="Permanent link">&para;</a></h3>
<p><strong>LLM weights</strong> store knowledge as:</p>
<ul>
<li><strong>Distributed patterns</strong> across billions of parameters where knowledge is internalized during training</li>
<li><strong>Implicit relationships</strong> learned through statistical associations in training data</li>
<li><strong>Generated responses</strong> via computational processes that activate learned patterns</li>
<li><strong>Fixed representations</strong> requiring retraining to update internalized knowledge</li>
</ul>
<p><strong>Vector stores</strong> maintain knowledge as:</p>
<ul>
<li><strong>Discrete vectors</strong> in searchable databases</li>
<li><strong>Explicit documents</strong> with clear provenance  </li>
<li><strong>Retrieved information</strong> through similarity search</li>
<li><strong>Dynamic content</strong> easily updated by adding/removing vectors</li>
</ul>
<h3 id="unified-understanding">Unified Understanding<a class="headerlink" href="#unified-understanding" title="Permanent link">&para;</a></h3>
<p>As explored in Section 5, both systems leverage similarity calculations but serve different purposes - LLMs use internal similarity for attention-based generation while vector stores use external similarity for document retrieval.</p>
<p>Both benefit from <strong>generation control parameters</strong>:</p>
<ul>
<li><strong>LLMs</strong>: Temperature, top-k, top-p for creativity vs. consistency</li>
<li><strong>Vector stores</strong>: Similarity thresholds, result limits for precision vs. recall</li>
</ul>
<h3 id="practical-integration">Practical Integration<a class="headerlink" href="#practical-integration" title="Permanent link">&para;</a></h3>
<p>Modern AI systems achieve optimal performance by combining both approaches:</p>
<ul>
<li><strong>Vector stores</strong> provide specific, current, and attributable information</li>
<li><strong>LLM weights</strong> contribute reasoning, synthesis, and natural language generation</li>
<li><strong>RAG architectures</strong> demonstrate how retrieval augments generation effectively</li>
</ul>
<h3 id="mathematical-foundation">Mathematical Foundation<a class="headerlink" href="#mathematical-foundation" title="Permanent link">&para;</a></h3>
<p>The underlying mathematics—from high-dimensional geometry to attention mechanisms—provides the theoretical foundation that makes both systems possible. For deeper mathematical understanding, see the comprehensive treatment in <a href="../transformers_math1/">transformers_math1.md</a> and <a href="../transformers_math2/">transformers_math2.md</a>.</p>
<p><strong>Final Insight</strong>: Understanding both knowledge storage paradigms enables practitioners to design more effective AI systems that leverage the strengths of each approach while mitigating their individual limitations.</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.sections", "navigation.top", "navigation.instant", "content.code.copy", "content.tabs.link", "toc.follow"], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
    
  </body>
</html>